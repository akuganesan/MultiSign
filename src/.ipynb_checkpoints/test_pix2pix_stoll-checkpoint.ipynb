{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "optional-price",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-64f50e7a4e6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlcm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfractions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_loader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCreateDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'data'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data\n",
    "from torch.autograd import Variable\n",
    "from torchvision import models\n",
    "\n",
    "import functools\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import os.path\n",
    "import time\n",
    "import fractions\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from subprocess import call\n",
    "def lcm(a,b): return abs(a * b)/fractions.gcd(a,b) if a and b else 0\n",
    "\n",
    "from models.models import create_model\n",
    "import util.util as util\n",
    "from util.visualizer import Visualizer\n",
    "\n",
    "import argparse\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "russian-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXTENSIONS = [\n",
    "    '.jpg', '.JPG', '.jpeg', '.JPEG',\n",
    "    '.png', '.PNG', '.ppm', '.PPM', '.bmp', '.BMP', '.tiff'\n",
    "]\n",
    "\n",
    "def is_image_file(filename):\n",
    "    return any(filename.endswith(extension) for extension in IMG_EXTENSIONS)\n",
    "\n",
    "def make_dataset(dir):\n",
    "    images = []\n",
    "    assert os.path.isdir(dir), '%s is not a valid directory' % dir\n",
    "\n",
    "    for root, _, fnames in sorted(os.walk(dir)):\n",
    "        for fname in fnames:\n",
    "            if is_image_file(fname):\n",
    "                path = os.path.join(root, fname)\n",
    "                images.append(path)\n",
    "\n",
    "    return images\n",
    "\n",
    "def default_loader(path):\n",
    "    return Image.open(path).convert('RGB')\n",
    "\n",
    "class ImageFolder(data.Dataset):\n",
    "\n",
    "    def __init__(self, root, transform=None, return_paths=False,\n",
    "                 loader=default_loader):\n",
    "        imgs = make_dataset(root)\n",
    "        if len(imgs) == 0:\n",
    "            raise(RuntimeError(\"Found 0 images in: \" + root + \"\\n\"\n",
    "                               \"Supported image extensions are: \" +\n",
    "                               \",\".join(IMG_EXTENSIONS)))\n",
    "\n",
    "        self.root = root\n",
    "        self.imgs = imgs\n",
    "        self.transform = transform\n",
    "        self.return_paths = return_paths\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        path = self.imgs[index]\n",
    "        img = self.loader(path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.return_paths:\n",
    "            return img, path\n",
    "        else:\n",
    "            return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "\n",
    "class BaseDataset(data.Dataset):\n",
    "    def __init__(self):\n",
    "        super(BaseDataset, self).__init__()\n",
    "\n",
    "    def name(self):\n",
    "        return 'BaseDataset'\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        pass\n",
    "\n",
    "def get_params(opt, size):\n",
    "    w, h = size\n",
    "    new_h = h\n",
    "    new_w = w\n",
    "    if opt.resize_or_crop == 'resize_and_crop':\n",
    "        new_h = new_w = opt.loadSize            \n",
    "    elif opt.resize_or_crop == 'scale_width_and_crop':\n",
    "        new_w = opt.loadSize\n",
    "        new_h = opt.loadSize * h // w\n",
    "\n",
    "    x = random.randint(0, np.maximum(0, new_w - opt.fineSize))\n",
    "    y = random.randint(0, np.maximum(0, new_h - opt.fineSize))\n",
    "    \n",
    "    flip = random.random() > 0.5\n",
    "    return {'crop_pos': (x, y), 'flip': flip}\n",
    "\n",
    "def get_transform(opt, params, method=Image.BICUBIC, normalize=True):\n",
    "    transform_list = []\n",
    "    if 'resize' in opt.resize_or_crop:\n",
    "        osize = [opt.loadSize, opt.loadSize]\n",
    "        transform_list.append(transforms.Scale(osize, method))   \n",
    "    elif 'scale_width' in opt.resize_or_crop:\n",
    "        transform_list.append(transforms.Lambda(lambda img: __scale_width(img, opt.loadSize, method)))\n",
    "        \n",
    "    if 'crop' in opt.resize_or_crop:\n",
    "        transform_list.append(transforms.Lambda(lambda img: __crop(img, params['crop_pos'], opt.fineSize)))\n",
    "\n",
    "    if opt.resize_or_crop == 'none':\n",
    "        base = float(2 ** opt.n_downsample_global)\n",
    "        if opt.netG == 'local':\n",
    "            base *= (2 ** opt.n_local_enhancers)\n",
    "        transform_list.append(transforms.Lambda(lambda img: __make_power_2(img, base, method)))\n",
    "\n",
    "    if opt.isTrain and not opt.no_flip:\n",
    "        transform_list.append(transforms.Lambda(lambda img: __flip(img, params['flip'])))\n",
    "\n",
    "    transform_list += [transforms.ToTensor()]\n",
    "\n",
    "    if normalize:\n",
    "        transform_list += [transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                (0.5, 0.5, 0.5))]\n",
    "    return transforms.Compose(transform_list)\n",
    "\n",
    "def normalize():    \n",
    "    return transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "\n",
    "def __make_power_2(img, base, method=Image.BICUBIC):\n",
    "    ow, oh = img.size        \n",
    "    h = int(round(oh / base) * base)\n",
    "    w = int(round(ow / base) * base)\n",
    "    if (h == oh) and (w == ow):\n",
    "        return img\n",
    "    return img.resize((w, h), method)\n",
    "\n",
    "def __scale_width(img, target_width, method=Image.BICUBIC):\n",
    "    ow, oh = img.size\n",
    "    if (ow == target_width):\n",
    "        return img    \n",
    "    w = target_width\n",
    "    h = int(target_width * oh / ow)    \n",
    "    return img.resize((w, h), method)\n",
    "\n",
    "def __crop(img, pos, size):\n",
    "    ow, oh = img.size\n",
    "    x1, y1 = pos\n",
    "    tw = th = size\n",
    "    if (ow > tw or oh > th):        \n",
    "        return img.crop((x1, y1, x1 + tw, y1 + th))\n",
    "    return img\n",
    "\n",
    "def __flip(img, flip):\n",
    "    if flip:\n",
    "        return img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    return img\n",
    "\n",
    "class AlignedDataset(BaseDataset):\n",
    "    def initialize(self, opt):\n",
    "        self.opt = opt\n",
    "        self.root = opt.dataroot    \n",
    "\n",
    "        ### input A (label maps)\n",
    "        dir_A = '_A' if self.opt.label_nc == 0 else '_label'\n",
    "        self.dir_A = os.path.join(opt.dataroot, opt.phase + dir_A)\n",
    "        self.A_paths = sorted(make_dataset(self.dir_A))\n",
    "\n",
    "        ### input B (real images)\n",
    "        if opt.isTrain:\n",
    "            dir_B = '_B' if self.opt.label_nc == 0 else '_img'\n",
    "            self.dir_B = os.path.join(opt.dataroot, opt.phase + dir_B)  \n",
    "            self.B_paths = sorted(make_dataset(self.dir_B))\n",
    "\n",
    "        ### instance maps\n",
    "        if not opt.no_instance:\n",
    "            self.dir_inst = os.path.join(opt.dataroot, opt.phase + '_inst')\n",
    "            self.inst_paths = sorted(make_dataset(self.dir_inst))\n",
    "\n",
    "        ### load precomputed instance-wise encoded features\n",
    "        if opt.load_features:                              \n",
    "            self.dir_feat = os.path.join(opt.dataroot, opt.phase + '_feat')\n",
    "            print('----------- loading features from %s ----------' % self.dir_feat)\n",
    "            self.feat_paths = sorted(make_dataset(self.dir_feat))\n",
    "\n",
    "        self.dataset_size = len(self.A_paths) \n",
    "      \n",
    "    def __getitem__(self, index):        \n",
    "        ### input A (label maps)\n",
    "        A_path = self.A_paths[index]              \n",
    "        A = Image.open(A_path)        \n",
    "        params = get_params(self.opt, A.size)\n",
    "        if self.opt.label_nc == 0:\n",
    "            transform_A = get_transform(self.opt, params)\n",
    "            A_tensor = transform_A(A.convert('RGB'))\n",
    "        else:\n",
    "            transform_A = get_transform(self.opt, params, method=Image.NEAREST, normalize=False)\n",
    "            A_tensor = transform_A(A) * 255.0\n",
    "\n",
    "        B_tensor = inst_tensor = feat_tensor = 0\n",
    "        ### input B (real images)\n",
    "        if self.opt.isTrain:\n",
    "            B_path = self.B_paths[index]   \n",
    "            B = Image.open(B_path).convert('RGB')\n",
    "            transform_B = get_transform(self.opt, params)      \n",
    "            B_tensor = transform_B(B)\n",
    "\n",
    "        ### if using instance maps        \n",
    "        if not self.opt.no_instance:\n",
    "            inst_path = self.inst_paths[index]\n",
    "            inst = Image.open(inst_path)\n",
    "            inst_tensor = transform_A(inst)\n",
    "\n",
    "            if self.opt.load_features:\n",
    "                feat_path = self.feat_paths[index]            \n",
    "                feat = Image.open(feat_path).convert('RGB')\n",
    "                norm = normalize()\n",
    "                feat_tensor = norm(transform_A(feat))                            \n",
    "\n",
    "        input_dict = {'label': A_tensor, 'inst': inst_tensor, 'image': B_tensor, \n",
    "                      'feat': feat_tensor, 'path': A_path}\n",
    "\n",
    "        return input_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.A_paths) // self.opt.batchSize * self.opt.batchSize\n",
    "\n",
    "    def name(self):\n",
    "        return 'AlignedDataset'\n",
    "\n",
    "class BaseDataLoader():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def initialize(self, opt):\n",
    "        self.opt = opt\n",
    "        pass\n",
    "\n",
    "    def load_data():\n",
    "        return None\n",
    "\n",
    "def CreateDataset(opt):\n",
    "    dataset = None\n",
    "    dataset = AlignedDataset()\n",
    "\n",
    "    print(\"dataset [%s] was created\" % (dataset.name()))\n",
    "    dataset.initialize(opt)\n",
    "    return dataset\n",
    "\n",
    "class CustomDatasetDataLoader(BaseDataLoader):\n",
    "    def name(self):\n",
    "        return 'CustomDatasetDataLoader'\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        BaseDataLoader.initialize(self, opt)\n",
    "        self.dataset = CreateDataset(opt)\n",
    "        self.dataloader = data.DataLoader(\n",
    "            self.dataset,\n",
    "            batch_size=opt.batchSize,\n",
    "            shuffle=not opt.serial_batches,\n",
    "            num_workers=int(opt.nThreads))\n",
    "\n",
    "    def load_data(self):\n",
    "        return self.dataloader\n",
    "\n",
    "    def __len__(self):\n",
    "        return min(len(self.dataset), self.opt.max_dataset_size)\n",
    "\n",
    "def CreateDataLoader(opt):\n",
    "    data_loader = CustomDatasetDataLoader()\n",
    "    print(data_loader.name())\n",
    "    data_loader.initialize(opt)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "younger-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Functions\n",
    "###############################################################################\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm2d') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "def get_norm_layer(norm_type='instance'):\n",
    "    if norm_type == 'batch':\n",
    "        norm_layer = functools.partial(nn.BatchNorm2d, affine=True)\n",
    "    elif norm_type == 'instance':\n",
    "        norm_layer = functools.partial(nn.InstanceNorm2d, affine=False)\n",
    "    else:\n",
    "        raise NotImplementedError('normalization layer [%s] is not found' % norm_type)\n",
    "    return norm_layer\n",
    "\n",
    "def define_G(input_nc, output_nc, ngf, netG, n_downsample_global=3, n_blocks_global=9, n_local_enhancers=1, \n",
    "             n_blocks_local=3, norm='instance', gpu_ids=[]):    \n",
    "    norm_layer = get_norm_layer(norm_type=norm)     \n",
    "    if netG == 'global':    \n",
    "        netG = GlobalGenerator(input_nc, output_nc, ngf, n_downsample_global, n_blocks_global, norm_layer)       \n",
    "    elif netG == 'local':        \n",
    "        netG = LocalEnhancer(input_nc, output_nc, ngf, n_downsample_global, n_blocks_global, \n",
    "                                  n_local_enhancers, n_blocks_local, norm_layer)\n",
    "    elif netG == 'encoder':\n",
    "        netG = Encoder(input_nc, output_nc, ngf, n_downsample_global, norm_layer)\n",
    "    else:\n",
    "        raise('generator not implemented!')\n",
    "    print(netG)\n",
    "    if len(gpu_ids) > 0:\n",
    "        assert(torch.cuda.is_available())   \n",
    "        netG.cuda(gpu_ids[0])\n",
    "    netG.apply(weights_init)\n",
    "    return netG\n",
    "\n",
    "def define_D(input_nc, ndf, n_layers_D, norm='instance', use_sigmoid=False, num_D=1, getIntermFeat=False, gpu_ids=[]):        \n",
    "    norm_layer = get_norm_layer(norm_type=norm)   \n",
    "    netD = MultiscaleDiscriminator(input_nc, ndf, n_layers_D, norm_layer, use_sigmoid, num_D, getIntermFeat)   \n",
    "    print(netD)\n",
    "    if len(gpu_ids) > 0:\n",
    "        assert(torch.cuda.is_available())\n",
    "        netD.cuda(gpu_ids[0])\n",
    "    netD.apply(weights_init)\n",
    "    return netD\n",
    "\n",
    "def print_network(net):\n",
    "    if isinstance(net, list):\n",
    "        net = net[0]\n",
    "    num_params = 0\n",
    "    for param in net.parameters():\n",
    "        num_params += param.numel()\n",
    "    print(net)\n",
    "    print('Total number of parameters: %d' % num_params)\n",
    "\n",
    "##############################################################################\n",
    "# Losses\n",
    "##############################################################################\n",
    "class GANLoss(nn.Module):\n",
    "    def __init__(self, use_lsgan=True, target_real_label=1.0, target_fake_label=0.0,\n",
    "                 tensor=torch.FloatTensor):\n",
    "        super(GANLoss, self).__init__()\n",
    "        self.real_label = target_real_label\n",
    "        self.fake_label = target_fake_label\n",
    "        self.real_label_var = None\n",
    "        self.fake_label_var = None\n",
    "        self.Tensor = tensor\n",
    "        if use_lsgan:\n",
    "            self.loss = nn.MSELoss()\n",
    "        else:\n",
    "            self.loss = nn.BCELoss()\n",
    "\n",
    "    def get_target_tensor(self, input, target_is_real):\n",
    "        target_tensor = None\n",
    "        if target_is_real:\n",
    "            create_label = ((self.real_label_var is None) or\n",
    "                            (self.real_label_var.numel() != input.numel()))\n",
    "            if create_label:\n",
    "                real_tensor = self.Tensor(input.size()).fill_(self.real_label)\n",
    "                self.real_label_var = Variable(real_tensor, requires_grad=False)\n",
    "            target_tensor = self.real_label_var\n",
    "        else:\n",
    "            create_label = ((self.fake_label_var is None) or\n",
    "                            (self.fake_label_var.numel() != input.numel()))\n",
    "            if create_label:\n",
    "                fake_tensor = self.Tensor(input.size()).fill_(self.fake_label)\n",
    "                self.fake_label_var = Variable(fake_tensor, requires_grad=False)\n",
    "            target_tensor = self.fake_label_var\n",
    "        return target_tensor\n",
    "\n",
    "    def __call__(self, input, target_is_real):\n",
    "        if isinstance(input[0], list):\n",
    "            loss = 0\n",
    "            for input_i in input:\n",
    "                pred = input_i[-1]\n",
    "                target_tensor = self.get_target_tensor(pred, target_is_real)\n",
    "                loss += self.loss(pred, target_tensor)\n",
    "            return loss\n",
    "        else:            \n",
    "            target_tensor = self.get_target_tensor(input[-1], target_is_real)\n",
    "            return self.loss(input[-1], target_tensor)\n",
    "\n",
    "class VGGLoss(nn.Module):\n",
    "    def __init__(self, gpu_ids):\n",
    "        super(VGGLoss, self).__init__()        \n",
    "        self.vgg = Vgg19().cuda()\n",
    "        self.criterion = nn.L1Loss()\n",
    "        self.weights = [1.0/32, 1.0/16, 1.0/8, 1.0/4, 1.0]        \n",
    "\n",
    "    def forward(self, x, y):              \n",
    "        x_vgg, y_vgg = self.vgg(x), self.vgg(y)\n",
    "        loss = 0\n",
    "        for i in range(len(x_vgg)):\n",
    "            loss += self.weights[i] * self.criterion(x_vgg[i], y_vgg[i].detach())        \n",
    "        return loss\n",
    "\n",
    "##############################################################################\n",
    "# Generator\n",
    "##############################################################################\n",
    "class LocalEnhancer(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf=32, n_downsample_global=3, n_blocks_global=9, \n",
    "                 n_local_enhancers=1, n_blocks_local=3, norm_layer=nn.BatchNorm2d, padding_type='reflect'):        \n",
    "        super(LocalEnhancer, self).__init__()\n",
    "        self.n_local_enhancers = n_local_enhancers\n",
    "        \n",
    "        ###### global generator model #####           \n",
    "        ngf_global = ngf * (2**n_local_enhancers)\n",
    "        model_global = GlobalGenerator(input_nc, output_nc, ngf_global, n_downsample_global, n_blocks_global, norm_layer).model        \n",
    "        model_global = [model_global[i] for i in range(len(model_global)-3)] # get rid of final convolution layers        \n",
    "        self.model = nn.Sequential(*model_global)                \n",
    "\n",
    "        ###### local enhancer layers #####\n",
    "        for n in range(1, n_local_enhancers+1):\n",
    "            ### downsample            \n",
    "            ngf_global = ngf * (2**(n_local_enhancers-n))\n",
    "            model_downsample = [nn.ReflectionPad2d(3), nn.Conv2d(input_nc, ngf_global, kernel_size=7, padding=0), \n",
    "                                norm_layer(ngf_global), nn.ReLU(True),\n",
    "                                nn.Conv2d(ngf_global, ngf_global * 2, kernel_size=3, stride=2, padding=1), \n",
    "                                norm_layer(ngf_global * 2), nn.ReLU(True)]\n",
    "            ### residual blocks\n",
    "            model_upsample = []\n",
    "            for i in range(n_blocks_local):\n",
    "                model_upsample += [ResnetBlock(ngf_global * 2, padding_type=padding_type, norm_layer=norm_layer)]\n",
    "\n",
    "            ### upsample\n",
    "            model_upsample += [nn.ConvTranspose2d(ngf_global * 2, ngf_global, kernel_size=3, stride=2, padding=1, output_padding=1), \n",
    "                               norm_layer(ngf_global), nn.ReLU(True)]      \n",
    "\n",
    "            ### final convolution\n",
    "            if n == n_local_enhancers:                \n",
    "                model_upsample += [nn.ReflectionPad2d(3), nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0), nn.Tanh()]                       \n",
    "            \n",
    "            setattr(self, 'model'+str(n)+'_1', nn.Sequential(*model_downsample))\n",
    "            setattr(self, 'model'+str(n)+'_2', nn.Sequential(*model_upsample))                  \n",
    "        \n",
    "        self.downsample = nn.AvgPool2d(3, stride=2, padding=[1, 1], count_include_pad=False)\n",
    "\n",
    "    def forward(self, input): \n",
    "        ### create input pyramid\n",
    "        input_downsampled = [input]\n",
    "        for i in range(self.n_local_enhancers):\n",
    "            input_downsampled.append(self.downsample(input_downsampled[-1]))\n",
    "\n",
    "        ### output at coarest level\n",
    "        output_prev = self.model(input_downsampled[-1])        \n",
    "        ### build up one layer at a time\n",
    "        for n_local_enhancers in range(1, self.n_local_enhancers+1):\n",
    "            model_downsample = getattr(self, 'model'+str(n_local_enhancers)+'_1')\n",
    "            model_upsample = getattr(self, 'model'+str(n_local_enhancers)+'_2')            \n",
    "            input_i = input_downsampled[self.n_local_enhancers-n_local_enhancers]            \n",
    "            output_prev = model_upsample(model_downsample(input_i) + output_prev)\n",
    "        return output_prev\n",
    "\n",
    "class GlobalGenerator(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf=64, n_downsampling=3, n_blocks=9, norm_layer=nn.BatchNorm2d, \n",
    "                 padding_type='reflect'):\n",
    "        assert(n_blocks >= 0)\n",
    "        super(GlobalGenerator, self).__init__()        \n",
    "        activation = nn.ReLU(True)        \n",
    "\n",
    "        model = [nn.ReflectionPad2d(3), nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0), norm_layer(ngf), activation]\n",
    "        ### downsample\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1),\n",
    "                      norm_layer(ngf * mult * 2), activation]\n",
    "\n",
    "        ### resnet blocks\n",
    "        mult = 2**n_downsampling\n",
    "        for i in range(n_blocks):\n",
    "            model += [ResnetBlock(ngf * mult, padding_type=padding_type, activation=activation, norm_layer=norm_layer)]\n",
    "        \n",
    "        ### upsample         \n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**(n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2), kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                       norm_layer(int(ngf * mult / 2)), activation]\n",
    "        model += [nn.ReflectionPad2d(3), nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0), nn.Tanh()]        \n",
    "        self.model = nn.Sequential(*model)\n",
    "            \n",
    "    def forward(self, input):\n",
    "        return self.model(input)             \n",
    "        \n",
    "# Define a resnet block\n",
    "class ResnetBlock(nn.Module):\n",
    "    def __init__(self, dim, padding_type, norm_layer, activation=nn.ReLU(True), use_dropout=False):\n",
    "        super(ResnetBlock, self).__init__()\n",
    "        self.conv_block = self.build_conv_block(dim, padding_type, norm_layer, activation, use_dropout)\n",
    "\n",
    "    def build_conv_block(self, dim, padding_type, norm_layer, activation, use_dropout):\n",
    "        conv_block = []\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p),\n",
    "                       norm_layer(dim),\n",
    "                       activation]\n",
    "        if use_dropout:\n",
    "            conv_block += [nn.Dropout(0.5)]\n",
    "\n",
    "        p = 0\n",
    "        if padding_type == 'reflect':\n",
    "            conv_block += [nn.ReflectionPad2d(1)]\n",
    "        elif padding_type == 'replicate':\n",
    "            conv_block += [nn.ReplicationPad2d(1)]\n",
    "        elif padding_type == 'zero':\n",
    "            p = 1\n",
    "        else:\n",
    "            raise NotImplementedError('padding [%s] is not implemented' % padding_type)\n",
    "        conv_block += [nn.Conv2d(dim, dim, kernel_size=3, padding=p),\n",
    "                       norm_layer(dim)]\n",
    "\n",
    "        return nn.Sequential(*conv_block)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x + self.conv_block(x)\n",
    "        return out\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_nc, output_nc, ngf=32, n_downsampling=4, norm_layer=nn.BatchNorm2d):\n",
    "        super(Encoder, self).__init__()        \n",
    "        self.output_nc = output_nc        \n",
    "\n",
    "        model = [nn.ReflectionPad2d(3), nn.Conv2d(input_nc, ngf, kernel_size=7, padding=0), \n",
    "                 norm_layer(ngf), nn.ReLU(True)]             \n",
    "        ### downsample\n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**i\n",
    "            model += [nn.Conv2d(ngf * mult, ngf * mult * 2, kernel_size=3, stride=2, padding=1),\n",
    "                      norm_layer(ngf * mult * 2), nn.ReLU(True)]\n",
    "\n",
    "        ### upsample         \n",
    "        for i in range(n_downsampling):\n",
    "            mult = 2**(n_downsampling - i)\n",
    "            model += [nn.ConvTranspose2d(ngf * mult, int(ngf * mult / 2), kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "                       norm_layer(int(ngf * mult / 2)), nn.ReLU(True)]        \n",
    "\n",
    "        model += [nn.ReflectionPad2d(3), nn.Conv2d(ngf, output_nc, kernel_size=7, padding=0), nn.Tanh()]\n",
    "        self.model = nn.Sequential(*model) \n",
    "\n",
    "    def forward(self, input, inst):\n",
    "        outputs = self.model(input)\n",
    "\n",
    "        # instance-wise average pooling\n",
    "        outputs_mean = outputs.clone()\n",
    "        inst_list = np.unique(inst.cpu().numpy().astype(int))        \n",
    "        for i in inst_list:\n",
    "            for b in range(input.size()[0]):\n",
    "                indices = (inst[b:b+1] == int(i)).nonzero() # n x 4            \n",
    "                for j in range(self.output_nc):\n",
    "                    output_ins = outputs[indices[:,0] + b, indices[:,1] + j, indices[:,2], indices[:,3]]                    \n",
    "                    mean_feat = torch.mean(output_ins).expand_as(output_ins)                                        \n",
    "                    outputs_mean[indices[:,0] + b, indices[:,1] + j, indices[:,2], indices[:,3]] = mean_feat                       \n",
    "        return outputs_mean\n",
    "\n",
    "class MultiscaleDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, \n",
    "                 use_sigmoid=False, num_D=3, getIntermFeat=False):\n",
    "        super(MultiscaleDiscriminator, self).__init__()\n",
    "        self.num_D = num_D\n",
    "        self.n_layers = n_layers\n",
    "        self.getIntermFeat = getIntermFeat\n",
    "     \n",
    "        for i in range(num_D):\n",
    "            netD = NLayerDiscriminator(input_nc, ndf, n_layers, norm_layer, use_sigmoid, getIntermFeat)\n",
    "            if getIntermFeat:                                \n",
    "                for j in range(n_layers+2):\n",
    "                    setattr(self, 'scale'+str(i)+'_layer'+str(j), getattr(netD, 'model'+str(j)))                                   \n",
    "            else:\n",
    "                setattr(self, 'layer'+str(i), netD.model)\n",
    "\n",
    "        self.downsample = nn.AvgPool2d(3, stride=2, padding=[1, 1], count_include_pad=False)\n",
    "\n",
    "    def singleD_forward(self, model, input):\n",
    "        if self.getIntermFeat:\n",
    "            result = [input]\n",
    "            for i in range(len(model)):\n",
    "                result.append(model[i](result[-1]))\n",
    "            return result[1:]\n",
    "        else:\n",
    "            return [model(input)]\n",
    "\n",
    "    def forward(self, input):        \n",
    "        num_D = self.num_D\n",
    "        result = []\n",
    "        input_downsampled = input\n",
    "        for i in range(num_D):\n",
    "            if self.getIntermFeat:\n",
    "                model = [getattr(self, 'scale'+str(num_D-1-i)+'_layer'+str(j)) for j in range(self.n_layers+2)]\n",
    "            else:\n",
    "                model = getattr(self, 'layer'+str(num_D-1-i))\n",
    "            result.append(self.singleD_forward(model, input_downsampled))\n",
    "            if i != (num_D-1):\n",
    "                input_downsampled = self.downsample(input_downsampled)\n",
    "        return result\n",
    "        \n",
    "# Defines the PatchGAN discriminator with the specified arguments.\n",
    "class NLayerDiscriminator(nn.Module):\n",
    "    def __init__(self, input_nc, ndf=64, n_layers=3, norm_layer=nn.BatchNorm2d, use_sigmoid=False, getIntermFeat=False):\n",
    "        super(NLayerDiscriminator, self).__init__()\n",
    "        self.getIntermFeat = getIntermFeat\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        kw = 4\n",
    "        padw = int(np.ceil((kw-1.0)/2))\n",
    "        sequence = [[nn.Conv2d(input_nc, ndf, kernel_size=kw, stride=2, padding=padw), nn.LeakyReLU(0.2, True)]]\n",
    "\n",
    "        nf = ndf\n",
    "        for n in range(1, n_layers):\n",
    "            nf_prev = nf\n",
    "            nf = min(nf * 2, 512)\n",
    "            sequence += [[\n",
    "                nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=2, padding=padw),\n",
    "                norm_layer(nf), nn.LeakyReLU(0.2, True)\n",
    "            ]]\n",
    "\n",
    "        nf_prev = nf\n",
    "        nf = min(nf * 2, 512)\n",
    "        sequence += [[\n",
    "            nn.Conv2d(nf_prev, nf, kernel_size=kw, stride=1, padding=padw),\n",
    "            norm_layer(nf),\n",
    "            nn.LeakyReLU(0.2, True)\n",
    "        ]]\n",
    "\n",
    "        sequence += [[nn.Conv2d(nf, 1, kernel_size=kw, stride=1, padding=padw)]]\n",
    "\n",
    "        if use_sigmoid:\n",
    "            sequence += [[nn.Sigmoid()]]\n",
    "\n",
    "        if getIntermFeat:\n",
    "            for n in range(len(sequence)):\n",
    "                setattr(self, 'model'+str(n), nn.Sequential(*sequence[n]))\n",
    "        else:\n",
    "            sequence_stream = []\n",
    "            for n in range(len(sequence)):\n",
    "                sequence_stream += sequence[n]\n",
    "            self.model = nn.Sequential(*sequence_stream)\n",
    "\n",
    "    def forward(self, input):\n",
    "        if self.getIntermFeat:\n",
    "            res = [input]\n",
    "            for n in range(self.n_layers+2):\n",
    "                model = getattr(self, 'model'+str(n))\n",
    "                res.append(model(res[-1]))\n",
    "            return res[1:]\n",
    "        else:\n",
    "            return self.model(input)        \n",
    "\n",
    "class Vgg19(torch.nn.Module):\n",
    "    def __init__(self, requires_grad=False):\n",
    "        super(Vgg19, self).__init__()\n",
    "        vgg_pretrained_features = models.vgg19(pretrained=True).features\n",
    "        self.slice1 = torch.nn.Sequential()\n",
    "        self.slice2 = torch.nn.Sequential()\n",
    "        self.slice3 = torch.nn.Sequential()\n",
    "        self.slice4 = torch.nn.Sequential()\n",
    "        self.slice5 = torch.nn.Sequential()\n",
    "        for x in range(2):\n",
    "            self.slice1.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(2, 7):\n",
    "            self.slice2.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(7, 12):\n",
    "            self.slice3.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(12, 21):\n",
    "            self.slice4.add_module(str(x), vgg_pretrained_features[x])\n",
    "        for x in range(21, 30):\n",
    "            self.slice5.add_module(str(x), vgg_pretrained_features[x])\n",
    "        if not requires_grad:\n",
    "            for param in self.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, X):\n",
    "        h_relu1 = self.slice1(X)\n",
    "        h_relu2 = self.slice2(h_relu1)        \n",
    "        h_relu3 = self.slice3(h_relu2)        \n",
    "        h_relu4 = self.slice4(h_relu3)        \n",
    "        h_relu5 = self.slice5(h_relu4)                \n",
    "        out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-clearing",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UIModel(BaseModel):\n",
    "    def name(self):\n",
    "        return 'UIModel'\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        assert(not opt.isTrain)\n",
    "        BaseModel.initialize(self, opt)\n",
    "        self.use_features = opt.instance_feat or opt.label_feat\n",
    "\n",
    "        netG_input_nc = opt.label_nc\n",
    "        if not opt.no_instance:\n",
    "            netG_input_nc += 1            \n",
    "        if self.use_features:   \n",
    "            netG_input_nc += opt.feat_num           \n",
    "\n",
    "        self.netG = define_G(netG_input_nc, opt.output_nc, opt.ngf, opt.netG, \n",
    "                                      opt.n_downsample_global, opt.n_blocks_global, opt.n_local_enhancers, \n",
    "                                      opt.n_blocks_local, opt.norm, gpu_ids=self.gpu_ids)            \n",
    "        self.load_network(self.netG, 'G', opt.which_epoch)\n",
    "\n",
    "        print('---------- Networks initialized -------------')\n",
    "\n",
    "    def toTensor(self, img, normalize=False):\n",
    "        tensor = torch.from_numpy(np.array(img, np.int32, copy=False))\n",
    "        tensor = tensor.view(1, img.size[1], img.size[0], len(img.mode))    \n",
    "        tensor = tensor.transpose(1, 2).transpose(1, 3).contiguous()\n",
    "        if normalize:\n",
    "            return (tensor.float()/255.0 - 0.5) / 0.5        \n",
    "        return tensor.float()\n",
    "\n",
    "    def load_image(self, label_path, inst_path, feat_path):\n",
    "        opt = self.opt\n",
    "        # read label map\n",
    "        label_img = Image.open(label_path)    \n",
    "        if label_path.find('face') != -1:\n",
    "            label_img = label_img.convert('L')\n",
    "        ow, oh = label_img.size    \n",
    "        w = opt.loadSize\n",
    "        h = int(w * oh / ow)    \n",
    "        label_img = label_img.resize((w, h), Image.NEAREST)\n",
    "        label_map = self.toTensor(label_img)           \n",
    "        \n",
    "        # onehot vector input for label map\n",
    "        self.label_map = label_map.cuda()\n",
    "        oneHot_size = (1, opt.label_nc, h, w)\n",
    "        input_label = self.Tensor(torch.Size(oneHot_size)).zero_()\n",
    "        self.input_label = input_label.scatter_(1, label_map.long().cuda(), 1.0)\n",
    "\n",
    "        # read instance map\n",
    "        if not opt.no_instance:\n",
    "            inst_img = Image.open(inst_path)        \n",
    "            inst_img = inst_img.resize((w, h), Image.NEAREST)            \n",
    "            self.inst_map = self.toTensor(inst_img).cuda()\n",
    "            self.edge_map = self.get_edges(self.inst_map)          \n",
    "            self.net_input = Variable(torch.cat((self.input_label, self.edge_map), dim=1), volatile=True)\n",
    "        else:\n",
    "            self.net_input = Variable(self.input_label, volatile=True)  \n",
    "        \n",
    "        self.features_clustered = np.load(feat_path).item()\n",
    "        self.object_map = self.inst_map if opt.instance_feat else self.label_map \n",
    "                       \n",
    "        object_np = self.object_map.cpu().numpy().astype(int) \n",
    "        self.feat_map = self.Tensor(1, opt.feat_num, h, w).zero_()                 \n",
    "        self.cluster_indices = np.zeros(self.opt.label_nc, np.uint8)\n",
    "        for i in np.unique(object_np):    \n",
    "            label = i if i < 1000 else i//1000\n",
    "            if label in self.features_clustered:\n",
    "                feat = self.features_clustered[label]\n",
    "                np.random.seed(i+1)\n",
    "                cluster_idx = np.random.randint(0, feat.shape[0])\n",
    "                self.cluster_indices[label] = cluster_idx\n",
    "                idx = (self.object_map == i).nonzero()                    \n",
    "                self.set_features(idx, feat, cluster_idx)\n",
    "\n",
    "        self.net_input_original = self.net_input.clone()        \n",
    "        self.label_map_original = self.label_map.clone()\n",
    "        self.feat_map_original = self.feat_map.clone()\n",
    "        if not opt.no_instance:\n",
    "            self.inst_map_original = self.inst_map.clone()        \n",
    "\n",
    "    def reset(self):\n",
    "        self.net_input = self.net_input_prev = self.net_input_original.clone()        \n",
    "        self.label_map = self.label_map_prev = self.label_map_original.clone()\n",
    "        self.feat_map = self.feat_map_prev = self.feat_map_original.clone()\n",
    "        if not self.opt.no_instance:\n",
    "            self.inst_map = self.inst_map_prev = self.inst_map_original.clone()\n",
    "        self.object_map = self.inst_map if self.opt.instance_feat else self.label_map \n",
    "\n",
    "    def undo(self):        \n",
    "        self.net_input = self.net_input_prev\n",
    "        self.label_map = self.label_map_prev\n",
    "        self.feat_map = self.feat_map_prev\n",
    "        if not self.opt.no_instance:\n",
    "            self.inst_map = self.inst_map_prev\n",
    "        self.object_map = self.inst_map if self.opt.instance_feat else self.label_map \n",
    "            \n",
    "    # get boundary map from instance map\n",
    "    def get_edges(self, t):\n",
    "        edge = torch.cuda.ByteTensor(t.size()).zero_()\n",
    "        edge[:,:,:,1:] = edge[:,:,:,1:] | (t[:,:,:,1:] != t[:,:,:,:-1])\n",
    "        edge[:,:,:,:-1] = edge[:,:,:,:-1] | (t[:,:,:,1:] != t[:,:,:,:-1])\n",
    "        edge[:,:,1:,:] = edge[:,:,1:,:] | (t[:,:,1:,:] != t[:,:,:-1,:])\n",
    "        edge[:,:,:-1,:] = edge[:,:,:-1,:] | (t[:,:,1:,:] != t[:,:,:-1,:])\n",
    "        return edge.float()\n",
    "\n",
    "    # change the label at the source position to the label at the target position\n",
    "    def change_labels(self, click_src, click_tgt): \n",
    "        y_src, x_src = click_src[0], click_src[1]\n",
    "        y_tgt, x_tgt = click_tgt[0], click_tgt[1]\n",
    "        label_src = int(self.label_map[0, 0, y_src, x_src])\n",
    "        inst_src = self.inst_map[0, 0, y_src, x_src]\n",
    "        label_tgt = int(self.label_map[0, 0, y_tgt, x_tgt])\n",
    "        inst_tgt = self.inst_map[0, 0, y_tgt, x_tgt]\n",
    "\n",
    "        idx_src = (self.inst_map == inst_src).nonzero()         \n",
    "        # need to change 3 things: label map, instance map, and feature map\n",
    "        if idx_src.shape:\n",
    "            # backup current maps\n",
    "            self.backup_current_state() \n",
    "\n",
    "            # change both the label map and the network input\n",
    "            self.label_map[idx_src[:,0], idx_src[:,1], idx_src[:,2], idx_src[:,3]] = label_tgt\n",
    "            self.net_input[idx_src[:,0], idx_src[:,1] + label_src, idx_src[:,2], idx_src[:,3]] = 0\n",
    "            self.net_input[idx_src[:,0], idx_src[:,1] + label_tgt, idx_src[:,2], idx_src[:,3]] = 1                                    \n",
    "            \n",
    "            # update the instance map (and the network input)\n",
    "            if inst_tgt > 1000:\n",
    "                # if different instances have different ids, give the new object a new id\n",
    "                tgt_indices = (self.inst_map > label_tgt * 1000) & (self.inst_map < (label_tgt+1) * 1000)\n",
    "                inst_tgt = self.inst_map[tgt_indices].max() + 1\n",
    "            self.inst_map[idx_src[:,0], idx_src[:,1], idx_src[:,2], idx_src[:,3]] = inst_tgt\n",
    "            self.net_input[:,-1,:,:] = self.get_edges(self.inst_map)\n",
    "\n",
    "            # also copy the source features to the target position      \n",
    "            idx_tgt = (self.inst_map == inst_tgt).nonzero()    \n",
    "            if idx_tgt.shape:\n",
    "                self.copy_features(idx_src, idx_tgt[0,:])\n",
    "\n",
    "        self.fake_image = util.tensor2im(self.single_forward(self.net_input, self.feat_map))\n",
    "\n",
    "    # add strokes of target label in the image\n",
    "    def add_strokes(self, click_src, label_tgt, bw, save):\n",
    "        # get the region of the new strokes (bw is the brush width)        \n",
    "        size = self.net_input.size()\n",
    "        h, w = size[2], size[3]\n",
    "        idx_src = torch.LongTensor(bw**2, 4).fill_(0)\n",
    "        for i in range(bw):\n",
    "            idx_src[i*bw:(i+1)*bw, 2] = min(h-1, max(0, click_src[0]-bw//2 + i))\n",
    "            for j in range(bw):\n",
    "                idx_src[i*bw+j, 3] = min(w-1, max(0, click_src[1]-bw//2 + j))\n",
    "        idx_src = idx_src.cuda()\n",
    "        \n",
    "        # again, need to update 3 things\n",
    "        if idx_src.shape:\n",
    "            # backup current maps\n",
    "            if save:\n",
    "                self.backup_current_state()\n",
    "\n",
    "            # update the label map (and the network input) in the stroke region            \n",
    "            self.label_map[idx_src[:,0], idx_src[:,1], idx_src[:,2], idx_src[:,3]] = label_tgt\n",
    "            for k in range(self.opt.label_nc):\n",
    "                self.net_input[idx_src[:,0], idx_src[:,1] + k, idx_src[:,2], idx_src[:,3]] = 0\n",
    "            self.net_input[idx_src[:,0], idx_src[:,1] + label_tgt, idx_src[:,2], idx_src[:,3]] = 1                 \n",
    "\n",
    "            # update the instance map (and the network input)\n",
    "            self.inst_map[idx_src[:,0], idx_src[:,1], idx_src[:,2], idx_src[:,3]] = label_tgt\n",
    "            self.net_input[:,-1,:,:] = self.get_edges(self.inst_map)\n",
    "            \n",
    "            # also update the features if available\n",
    "            if self.opt.instance_feat:                                            \n",
    "                feat = self.features_clustered[label_tgt]\n",
    "                #np.random.seed(label_tgt+1)   \n",
    "                #cluster_idx = np.random.randint(0, feat.shape[0])\n",
    "                cluster_idx = self.cluster_indices[label_tgt]\n",
    "                self.set_features(idx_src, feat, cluster_idx)                                                  \n",
    "        \n",
    "        self.fake_image = util.tensor2im(self.single_forward(self.net_input, self.feat_map))\n",
    "\n",
    "    # add an object to the clicked position with selected style\n",
    "    def add_objects(self, click_src, label_tgt, mask, style_id=0):\n",
    "        y, x = click_src[0], click_src[1]\n",
    "        mask = np.transpose(mask, (2, 0, 1))[np.newaxis,...]        \n",
    "        idx_src = torch.from_numpy(mask).cuda().nonzero()        \n",
    "        idx_src[:,2] += y\n",
    "        idx_src[:,3] += x\n",
    "\n",
    "        # backup current maps\n",
    "        self.backup_current_state()\n",
    "\n",
    "        # update label map\n",
    "        self.label_map[idx_src[:,0], idx_src[:,1], idx_src[:,2], idx_src[:,3]] = label_tgt        \n",
    "        for k in range(self.opt.label_nc):\n",
    "            self.net_input[idx_src[:,0], idx_src[:,1] + k, idx_src[:,2], idx_src[:,3]] = 0\n",
    "        self.net_input[idx_src[:,0], idx_src[:,1] + label_tgt, idx_src[:,2], idx_src[:,3]] = 1            \n",
    "\n",
    "        # update instance map\n",
    "        self.inst_map[idx_src[:,0], idx_src[:,1], idx_src[:,2], idx_src[:,3]] = label_tgt\n",
    "        self.net_input[:,-1,:,:] = self.get_edges(self.inst_map)\n",
    "                \n",
    "        # update feature map\n",
    "        self.set_features(idx_src, self.feat, style_id)                \n",
    "        \n",
    "        self.fake_image = util.tensor2im(self.single_forward(self.net_input, self.feat_map))\n",
    "\n",
    "    def single_forward(self, net_input, feat_map):\n",
    "        net_input = torch.cat((net_input, feat_map), dim=1)\n",
    "        fake_image = self.netG.forward(net_input)\n",
    "\n",
    "        if fake_image.size()[0] == 1:\n",
    "            return fake_image.data[0]        \n",
    "        return fake_image.data\n",
    "\n",
    "\n",
    "    # generate all outputs for different styles\n",
    "    def style_forward(self, click_pt, style_id=-1):           \n",
    "        if click_pt is None:            \n",
    "            self.fake_image = util.tensor2im(self.single_forward(self.net_input, self.feat_map))\n",
    "            self.crop = None\n",
    "            self.mask = None        \n",
    "        else:                       \n",
    "            instToChange = int(self.object_map[0, 0, click_pt[0], click_pt[1]])\n",
    "            self.instToChange = instToChange\n",
    "            label = instToChange if instToChange < 1000 else instToChange//1000        \n",
    "            self.feat = self.features_clustered[label]\n",
    "            self.fake_image = []\n",
    "            self.mask = self.object_map == instToChange\n",
    "            idx = self.mask.nonzero()\n",
    "            self.get_crop_region(idx)            \n",
    "            if idx.size():                \n",
    "                if style_id == -1:\n",
    "                    (min_y, min_x, max_y, max_x) = self.crop\n",
    "                    ### original\n",
    "                    for cluster_idx in range(self.opt.multiple_output):\n",
    "                        self.set_features(idx, self.feat, cluster_idx)\n",
    "                        fake_image = self.single_forward(self.net_input, self.feat_map)\n",
    "                        fake_image = util.tensor2im(fake_image[:,min_y:max_y,min_x:max_x])\n",
    "                        self.fake_image.append(fake_image)    \n",
    "                    \"\"\"### To speed up previewing different style results, either crop or downsample the label maps\n",
    "                    if instToChange > 1000:\n",
    "                        (min_y, min_x, max_y, max_x) = self.crop                                                \n",
    "                        ### crop                                                \n",
    "                        _, _, h, w = self.net_input.size()\n",
    "                        offset = 512\n",
    "                        y_start, x_start = max(0, min_y-offset), max(0, min_x-offset)\n",
    "                        y_end, x_end = min(h, (max_y + offset)), min(w, (max_x + offset))\n",
    "                        y_region = slice(y_start, y_start+(y_end-y_start)//16*16)\n",
    "                        x_region = slice(x_start, x_start+(x_end-x_start)//16*16)\n",
    "                        net_input = self.net_input[:,:,y_region,x_region]                    \n",
    "                        for cluster_idx in range(self.opt.multiple_output):  \n",
    "                            self.set_features(idx, self.feat, cluster_idx)\n",
    "                            fake_image = self.single_forward(net_input, self.feat_map[:,:,y_region,x_region])                            \n",
    "                            fake_image = util.tensor2im(fake_image[:,min_y-y_start:max_y-y_start,min_x-x_start:max_x-x_start])\n",
    "                            self.fake_image.append(fake_image)\n",
    "                    else:\n",
    "                        ### downsample\n",
    "                        (min_y, min_x, max_y, max_x) = [crop//2 for crop in self.crop]                    \n",
    "                        net_input = self.net_input[:,:,::2,::2]                    \n",
    "                        size = net_input.size()\n",
    "                        net_input_batch = net_input.expand(self.opt.multiple_output, size[1], size[2], size[3])             \n",
    "                        for cluster_idx in range(self.opt.multiple_output):  \n",
    "                            self.set_features(idx, self.feat, cluster_idx)\n",
    "                            feat_map = self.feat_map[:,:,::2,::2]\n",
    "                            if cluster_idx == 0:\n",
    "                                feat_map_batch = feat_map\n",
    "                            else:\n",
    "                                feat_map_batch = torch.cat((feat_map_batch, feat_map), dim=0)\n",
    "                        fake_image_batch = self.single_forward(net_input_batch, feat_map_batch)\n",
    "                        for i in range(self.opt.multiple_output):\n",
    "                            self.fake_image.append(util.tensor2im(fake_image_batch[i,:,min_y:max_y,min_x:max_x]))\"\"\"\n",
    "                                        \n",
    "                else:\n",
    "                    self.set_features(idx, self.feat, style_id)\n",
    "                    self.cluster_indices[label] = style_id\n",
    "                    self.fake_image = util.tensor2im(self.single_forward(self.net_input, self.feat_map))        \n",
    "\n",
    "    def backup_current_state(self):\n",
    "        self.net_input_prev = self.net_input.clone()\n",
    "        self.label_map_prev = self.label_map.clone() \n",
    "        self.inst_map_prev = self.inst_map.clone() \n",
    "        self.feat_map_prev = self.feat_map.clone() \n",
    "\n",
    "    # crop the ROI and get the mask of the object\n",
    "    def get_crop_region(self, idx):\n",
    "        size = self.net_input.size()\n",
    "        h, w = size[2], size[3]\n",
    "        min_y, min_x = idx[:,2].min(), idx[:,3].min()\n",
    "        max_y, max_x = idx[:,2].max(), idx[:,3].max()             \n",
    "        crop_min = 128\n",
    "        if max_y - min_y < crop_min:\n",
    "            min_y = max(0, (max_y + min_y) // 2 - crop_min // 2)\n",
    "            max_y = min(h-1, min_y + crop_min)\n",
    "        if max_x - min_x < crop_min:\n",
    "            min_x = max(0, (max_x + min_x) // 2 - crop_min // 2)\n",
    "            max_x = min(w-1, min_x + crop_min)\n",
    "        self.crop = (min_y, min_x, max_y, max_x)           \n",
    "        self.mask = self.mask[:,:, min_y:max_y, min_x:max_x]\n",
    "\n",
    "    # update the feature map once a new object is added or the label is changed\n",
    "    def update_features(self, cluster_idx, mask=None, click_pt=None):        \n",
    "        self.feat_map_prev = self.feat_map.clone()\n",
    "        # adding a new object\n",
    "        if mask is not None:\n",
    "            y, x = click_pt[0], click_pt[1]\n",
    "            mask = np.transpose(mask, (2,0,1))[np.newaxis,...]        \n",
    "            idx = torch.from_numpy(mask).cuda().nonzero()        \n",
    "            idx[:,2] += y\n",
    "            idx[:,3] += x    \n",
    "        # changing the label of an existing object \n",
    "        else:            \n",
    "            idx = (self.object_map == self.instToChange).nonzero()              \n",
    "\n",
    "        # update feature map\n",
    "        self.set_features(idx, self.feat, cluster_idx)        \n",
    "\n",
    "    # set the class features to the target feature\n",
    "    def set_features(self, idx, feat, cluster_idx):        \n",
    "        for k in range(self.opt.feat_num):\n",
    "            self.feat_map[idx[:,0], idx[:,1] + k, idx[:,2], idx[:,3]] = feat[cluster_idx, k] \n",
    "\n",
    "    # copy the features at the target position to the source position\n",
    "    def copy_features(self, idx_src, idx_tgt):        \n",
    "        for k in range(self.opt.feat_num):\n",
    "            val = self.feat_map[idx_tgt[0], idx_tgt[1] + k, idx_tgt[2], idx_tgt[3]]\n",
    "            self.feat_map[idx_src[:,0], idx_src[:,1] + k, idx_src[:,2], idx_src[:,3]] = val \n",
    "\n",
    "    def get_current_visuals(self, getLabel=False):                              \n",
    "        mask = self.mask     \n",
    "        if self.mask is not None:\n",
    "            mask = np.transpose(self.mask[0].cpu().float().numpy(), (1,2,0)).astype(np.uint8)        \n",
    "\n",
    "        dict_list = [('fake_image', self.fake_image), ('mask', mask)]\n",
    "\n",
    "        if getLabel: # only output label map if needed to save bandwidth\n",
    "            label = util.tensor2label(self.net_input.data[0], self.opt.label_nc)                    \n",
    "            dict_list += [('label', label)]\n",
    "\n",
    "        return OrderedDict(dict_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "palestinian-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(opt):\n",
    "    if opt.model == 'pix2pixHD':\n",
    "        from .pix2pixHD_model import Pix2PixHDModel, InferenceModel\n",
    "        if opt.isTrain:\n",
    "            model = Pix2PixHDModel()\n",
    "        else:\n",
    "            model = InferenceModel()\n",
    "    else:\n",
    "        from .ui_model import UIModel\n",
    "        model = UIModel()\n",
    "    model.initialize(opt)\n",
    "    if opt.verbose:\n",
    "        print(\"model [%s] was created\" % (model.name()))\n",
    "\n",
    "    if opt.isTrain and len(opt.gpu_ids):\n",
    "        model = torch.nn.DataParallel(model, device_ids=opt.gpu_ids)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "analyzed-forest",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePool():\n",
    "    def __init__(self, pool_size):\n",
    "        self.pool_size = pool_size\n",
    "        if self.pool_size > 0:\n",
    "            self.num_imgs = 0\n",
    "            self.images = []\n",
    "\n",
    "    def query(self, images):\n",
    "        if self.pool_size == 0:\n",
    "            return images\n",
    "        return_images = []\n",
    "        for image in images.data:\n",
    "            image = torch.unsqueeze(image, 0)\n",
    "            if self.num_imgs < self.pool_size:\n",
    "                self.num_imgs = self.num_imgs + 1\n",
    "                self.images.append(image)\n",
    "                return_images.append(image)\n",
    "            else:\n",
    "                p = random.uniform(0, 1)\n",
    "                if p > 0.5:\n",
    "                    random_id = random.randint(0, self.pool_size-1)\n",
    "                    tmp = self.images[random_id].clone()\n",
    "                    self.images[random_id] = image\n",
    "                    return_images.append(tmp)\n",
    "                else:\n",
    "                    return_images.append(image)\n",
    "        return_images = Variable(torch.cat(return_images, 0))\n",
    "        return return_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "academic-grammar",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import sys\n",
    "\n",
    "class BaseModel(torch.nn.Module):\n",
    "    def name(self):\n",
    "        return 'BaseModel'\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        self.opt = opt\n",
    "        self.gpu_ids = opt.gpu_ids\n",
    "        self.isTrain = opt.isTrain\n",
    "        self.Tensor = torch.cuda.FloatTensor if self.gpu_ids else torch.Tensor\n",
    "        self.save_dir = os.path.join(opt.checkpoints_dir, opt.name)\n",
    "\n",
    "    def set_input(self, input):\n",
    "        self.input = input\n",
    "\n",
    "    def forward(self):\n",
    "        pass\n",
    "\n",
    "    # used in test time, no backprop\n",
    "    def test(self):\n",
    "        pass\n",
    "\n",
    "    def get_image_paths(self):\n",
    "        pass\n",
    "\n",
    "    def optimize_parameters(self):\n",
    "        pass\n",
    "\n",
    "    def get_current_visuals(self):\n",
    "        return self.input\n",
    "\n",
    "    def get_current_errors(self):\n",
    "        return {}\n",
    "\n",
    "    def save(self, label):\n",
    "        pass\n",
    "\n",
    "    # helper saving function that can be used by subclasses\n",
    "    def save_network(self, network, network_label, epoch_label, gpu_ids):\n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        save_path = os.path.join(self.save_dir, save_filename)\n",
    "        torch.save(network.cpu().state_dict(), save_path)\n",
    "        if len(gpu_ids) and torch.cuda.is_available():\n",
    "            network.cuda()\n",
    "\n",
    "    # helper loading function that can be used by subclasses\n",
    "    def load_network(self, network, network_label, epoch_label, save_dir=''):        \n",
    "        save_filename = '%s_net_%s.pth' % (epoch_label, network_label)\n",
    "        if not save_dir:\n",
    "            save_dir = self.save_dir\n",
    "        save_path = os.path.join(save_dir, save_filename)        \n",
    "        if not os.path.isfile(save_path):\n",
    "            print('%s not exists yet!' % save_path)\n",
    "            if network_label == 'G':\n",
    "                raise('Generator must exist!')\n",
    "        else:\n",
    "            #network.load_state_dict(torch.load(save_path))\n",
    "            try:\n",
    "                network.load_state_dict(torch.load(save_path))\n",
    "            except:   \n",
    "                pretrained_dict = torch.load(save_path)                \n",
    "                model_dict = network.state_dict()\n",
    "                try:\n",
    "                    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}                    \n",
    "                    network.load_state_dict(pretrained_dict)\n",
    "                    if self.opt.verbose:\n",
    "                        print('Pretrained network %s has excessive layers; Only loading layers that are used' % network_label)\n",
    "                except:\n",
    "                    print('Pretrained network %s has fewer layers; The following are not initialized:' % network_label)\n",
    "                    for k, v in pretrained_dict.items():                      \n",
    "                        if v.size() == model_dict[k].size():\n",
    "                            model_dict[k] = v\n",
    "\n",
    "                    if sys.version_info >= (3,0):\n",
    "                        not_initialized = set()\n",
    "                    else:\n",
    "                        from sets import Set\n",
    "                        not_initialized = Set()                    \n",
    "\n",
    "                    for k, v in model_dict.items():\n",
    "                        if k not in pretrained_dict or v.size() != pretrained_dict[k].size():\n",
    "                            not_initialized.add(k.split('.')[0])\n",
    "                    \n",
    "                    print(sorted(not_initialized))\n",
    "                    network.load_state_dict(model_dict)                  \n",
    "\n",
    "    def update_learning_rate():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pix2PixHDModel(BaseModel):\n",
    "    def name(self):\n",
    "        return 'Pix2PixHDModel'\n",
    "\n",
    "    def init_loss_filter(self, use_gan_feat_loss, use_vgg_loss):\n",
    "        flags = (True, use_gan_feat_loss, use_vgg_loss, True, True, False)\n",
    "\n",
    "        def loss_filter(g_gan, g_gan_feat, g_vgg, d_real, d_fake, l1):\n",
    "            return [l for (l, f) in zip((g_gan, g_gan_feat, g_vgg, d_real, d_fake, l1), flags) if f]\n",
    "\n",
    "        return loss_filter\n",
    "\n",
    "    def initialize(self, opt):\n",
    "        BaseModel.initialize(self, opt)\n",
    "        if opt.resize_or_crop != 'none' or not opt.isTrain:  # when training at full res this causes OOM\n",
    "            torch.backends.cudnn.benchmark = True\n",
    "        self.isTrain = opt.isTrain\n",
    "        self.use_features = opt.instance_feat or opt.label_feat\n",
    "        self.gen_features = self.use_features and not self.opt.load_features\n",
    "        input_nc = opt.label_nc if opt.label_nc != 0 else opt.input_nc\n",
    "\n",
    "        #self.prev = Variable(torch.cuda.FloatTensor(1, 3, 720, 1280).fill_(0).data, requires_grad=True)\n",
    "        #self.prev_real = Variable(torch.cuda.FloatTensor(1, 3, 720, 1280).fill_(0).data, requires_grad=True)\n",
    "        ##### define networks\n",
    "        # Generator network\n",
    "        netG_input_nc = input_nc\n",
    "        if not opt.no_instance:\n",
    "            netG_input_nc += 1\n",
    "        #if opt.use_rgb:\n",
    "            #netG_input_nc += 3\n",
    "        if self.use_features:\n",
    "            netG_input_nc += opt.feat_num\n",
    "        self.netG = define_G(netG_input_nc, opt.output_nc, opt.ngf, opt.netG,\n",
    "                                      opt.n_downsample_global, opt.n_blocks_global, opt.n_local_enhancers,\n",
    "                                      opt.n_blocks_local, opt.norm, gpu_ids=self.gpu_ids)\n",
    "\n",
    "        # Discriminator network\n",
    "        if self.isTrain:\n",
    "            use_sigmoid = opt.no_lsgan\n",
    "            netD_input_nc = input_nc + opt.output_nc\n",
    "            if not opt.no_instance:\n",
    "                netD_input_nc += 1\n",
    "            #if opt.use_rgb:\n",
    "                #netD_input_nc += 3\n",
    "            self.netD = define_D(netD_input_nc, opt.ndf, opt.n_layers_D, opt.norm, use_sigmoid,\n",
    "                                          opt.num_D, not opt.no_ganFeat_loss, gpu_ids=self.gpu_ids)\n",
    "\n",
    "        ### Encoder network\n",
    "        if self.gen_features:\n",
    "            self.netE = define_G(opt.output_nc, opt.feat_num, opt.nef, 'encoder',\n",
    "                                          opt.n_downsample_E, norm=opt.norm, gpu_ids=self.gpu_ids)\n",
    "        if self.opt.verbose:\n",
    "            print('---------- Networks initialized -------------')\n",
    "\n",
    "        # load networks\n",
    "        if not self.isTrain or opt.continue_train or opt.load_pretrain:\n",
    "            pretrained_path = '' if not self.isTrain else opt.load_pretrain\n",
    "            self.load_network(self.netG, 'G', opt.which_epoch, pretrained_path)\n",
    "            if self.isTrain:\n",
    "                self.load_network(self.netD, 'D', opt.which_epoch, pretrained_path)\n",
    "            if self.gen_features:\n",
    "                self.load_network(self.netE, 'E', opt.which_epoch, pretrained_path)\n",
    "\n",
    "                # set loss functions and optimizers\n",
    "        if self.isTrain:\n",
    "            if opt.pool_size > 0 and (len(self.gpu_ids)) > 1:\n",
    "                raise NotImplementedError(\"Fake Pool Not Implemented for MultiGPU\")\n",
    "            self.fake_pool = ImagePool(opt.pool_size)\n",
    "            self.old_lr = opt.lr\n",
    "\n",
    "            # define loss functions\n",
    "            self.loss_filter = self.init_loss_filter(not opt.no_ganFeat_loss, not opt.no_vgg_loss)\n",
    "\n",
    "            self.criterionGAN = networks.GANLoss(use_lsgan=not opt.no_lsgan, tensor=self.Tensor)\n",
    "            self.criterionFeat = torch.nn.L1Loss()\n",
    "            if not opt.no_vgg_loss:\n",
    "                self.criterionVGG = networks.VGGLoss(self.gpu_ids)\n",
    "\n",
    "            # Names so we can breakout loss\n",
    "            self.loss_names = self.loss_filter('G_GAN', 'G_GAN_Feat', 'G_VGG', 'D_real', 'D_fake', 'L1')\n",
    "\n",
    "            # initialize optimizers\n",
    "            # optimizer G\n",
    "            if opt.niter_fix_global > 0:\n",
    "                import sys\n",
    "                if sys.version_info >= (3, 0):\n",
    "                    finetune_list = set()\n",
    "                else:\n",
    "                    from sets import Set\n",
    "                    finetune_list = Set()\n",
    "\n",
    "                params_dict = dict(self.netG.named_parameters())\n",
    "                params = []\n",
    "                for key, value in params_dict.items():\n",
    "                    if key.startswith('model' + str(opt.n_local_enhancers)):\n",
    "                        params += [value]\n",
    "                        finetune_list.add(key.split('.')[0])\n",
    "                print(\n",
    "                    '------------- Only training the local enhancer network (for %d epochs) ------------' % opt.niter_fix_global)\n",
    "                print('The layers that are finetuned are ', sorted(finetune_list))\n",
    "            else:\n",
    "                params = list(self.netG.parameters())\n",
    "            if self.gen_features:\n",
    "                params += list(self.netE.parameters())\n",
    "            self.optimizer_G = torch.optim.Adam(params, lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "\n",
    "            # optimizer D\n",
    "            params = list(self.netD.parameters())\n",
    "            self.optimizer_D = torch.optim.Adam(params, lr=opt.lr, betas=(opt.beta1, 0.999))\n",
    "\n",
    "    def encode_input(self, label_map, inst_map=None, real_image=None, feat_map=None, infer=False):\n",
    "        if self.opt.label_nc == 0:\n",
    "            input_label = label_map.data.cuda()\n",
    "        else:\n",
    "            # create one-hot vector for label map\n",
    "            size = label_map.size()\n",
    "            oneHot_size = (size[0], self.opt.label_nc, size[2], size[3])\n",
    "            input_label = torch.cuda.FloatTensor(torch.Size(oneHot_size)).zero_()\n",
    "            input_label = input_label.scatter_(1, label_map.data.long().cuda(), 1.0)\n",
    "            if self.opt.data_type == 16:\n",
    "                input_label = input_label.half()\n",
    "\n",
    "        # get edges from instance map\n",
    "        if not self.opt.no_instance:\n",
    "            inst_map = inst_map.data.cuda()\n",
    "            edge_map = self.get_edges(inst_map)\n",
    "            input_label = torch.cat((input_label, edge_map), dim=1)\n",
    "        input_label = Variable(input_label, volatile=infer)\n",
    "\n",
    "        # real images for training\n",
    "        if real_image is not None:\n",
    "            real_image = Variable(real_image.data.cuda())\n",
    "\n",
    "        # instance map for feature encoding\n",
    "        if self.use_features:\n",
    "            # get precomputed feature maps\n",
    "            if self.opt.load_features:\n",
    "                feat_map = Variable(feat_map.data.cuda())\n",
    "\n",
    "        return input_label, inst_map, real_image, feat_map\n",
    "\n",
    "    def discriminate(self, input_label, test_image, use_pool=False):\n",
    "        #input_concat = torch.cat((input_label, test_image.detach(), prev.detach()), dim=1)\n",
    "        # input_concat = torch.cat((input_label, prev.detach(), (test_image.detach() - prev.detach())), dim=1)\n",
    "        input_concat = torch.cat((input_label, test_image.detach()), dim=1)\n",
    "        if use_pool:\n",
    "            fake_query = self.fake_pool.query(input_concat)\n",
    "            return self.netD.forward(fake_query)\n",
    "        else:\n",
    "            return self.netD.forward(input_concat)\n",
    "\n",
    "    def forward(self, label, inst, image, feat, infer=False):\n",
    "        # Encode Inputs\n",
    "        input_label, inst_map, real_image, feat_map = self.encode_input(label, inst, image, feat)\n",
    "\n",
    "        # Fake Generation\n",
    "        if self.use_features:\n",
    "            if not self.opt.load_features:\n",
    "                feat_map = self.netE.forward(real_image, inst_map)\n",
    "            input_concat = torch.cat((input_label, feat_map), dim=1)\n",
    "        else:\n",
    "            input_concat = input_label\n",
    "            #input_concat = torch.cat((input_label, self.prev), dim=1)\n",
    "        fake_image = self.netG.forward(input_concat)\n",
    "\n",
    "        # Fake Detection and Loss\n",
    "        #pred_fake_pool = self.discriminate(input_label, fake_image, self.prev, use_pool=False)\n",
    "        pred_fake_pool = self.discriminate(input_label, fake_image, use_pool=False)\n",
    "        loss_D_fake = self.criterionGAN(pred_fake_pool, False)\n",
    "\n",
    "        # Real Detection and Loss\n",
    "        #pred_real = self.discriminate(input_label, real_image, self.prev_real, use_pool=False)\n",
    "        pred_real = self.discriminate(input_label, real_image,  use_pool=False)\n",
    "        loss_D_real = self.criterionGAN(pred_real, True)\n",
    "\n",
    "        # GAN loss (Fake Passability Loss)\n",
    "        #pred_fake = self.netD.forward(torch.cat((input_label, fake_image, self.prev), dim=1))\n",
    "        # pred_fake = self.netD.forward(torch.cat((input_label, (fake_image - self.prev), self.prev), dim=1))\n",
    "        pred_fake = self.netD.forward(torch.cat((input_label, fake_image), dim=1))\n",
    "        loss_G_GAN = self.criterionGAN(pred_fake, True)\n",
    "\n",
    "        # GAN feature matching loss\n",
    "        loss_G_GAN_Feat = 0\n",
    "        if not self.opt.no_ganFeat_loss:\n",
    "            feat_weights = 4.0 / (self.opt.n_layers_D + 1)\n",
    "            D_weights = 1.0 / self.opt.num_D\n",
    "            for i in range(self.opt.num_D):\n",
    "                for j in range(len(pred_fake[i]) - 1):\n",
    "                    loss_G_GAN_Feat += D_weights * feat_weights * \\\n",
    "                                       self.criterionFeat(pred_fake[i][j],\n",
    "                                                          pred_real[i][j].detach()) * self.opt.lambda_feat\n",
    "\n",
    "        # VGG feature matching loss\n",
    "        loss_G_VGG = 0\n",
    "        if not self.opt.no_vgg_loss:\n",
    "            loss_G_VGG = self.criterionVGG(fake_image, real_image) * self.opt.lambda_feat\n",
    "\n",
    "        L1_loss = torch.abs(real_image - fake_image)\n",
    "\n",
    "        self.prev = Variable(fake_image.data, requires_grad=True)\n",
    "        self.prev_real = Variable(real_image.data, requires_grad=True)\n",
    "\n",
    "        # Only return the fake_B image if necessary to save BW\n",
    "        return [self.loss_filter(loss_G_GAN, loss_G_GAN_Feat, loss_G_VGG, loss_D_real, loss_D_fake, L1_loss),\n",
    "                None if not infer else fake_image]\n",
    "\n",
    "        # return [self.loss_filter(loss_G_GAN, loss_G_GAN_Feat, loss_G_VGG, loss_D_real, loss_D_fake), fake_image]\n",
    "\n",
    "    def inference(self, label, inst):\n",
    "        # Encode Inputs\n",
    "        input_label, inst_map, _, _ = self.encode_input(Variable(label), Variable(inst), infer=True)\n",
    "\n",
    "        # Fake Generation\n",
    "        if self.use_features:\n",
    "            # sample clusters from precomputed features\n",
    "            feat_map = self.sample_features(inst_map)\n",
    "\n",
    "            input_concat = torch.cat((input_label, feat_map), dim=1)\n",
    "        else:\n",
    "            # input_concat = input_label\n",
    "            input_concat = torch.cat((input_label, self.prev), dim=1)\n",
    "        if torch.__version__.startswith('0.4'):\n",
    "            with torch.no_grad():\n",
    "                fake_image = self.netG.forward(input_concat)\n",
    "        else:\n",
    "            fake_image = self.netG.forward(input_concat)\n",
    "        return fake_image\n",
    "\n",
    "    def sample_features(self, inst):\n",
    "        # read precomputed feature clusters\n",
    "        cluster_path = os.path.join(self.opt.checkpoints_dir, self.opt.name, self.opt.cluster_path)\n",
    "        features_clustered = np.load(cluster_path).item()\n",
    "\n",
    "        # randomly sample from the feature clusters\n",
    "        inst_np = inst.cpu().numpy().astype(int)\n",
    "        feat_map = self.Tensor(inst.size()[0], self.opt.feat_num, inst.size()[2], inst.size()[3])\n",
    "        for i in np.unique(inst_np):\n",
    "            label = i if i < 1000 else i // 1000\n",
    "            if label in features_clustered:\n",
    "                feat = features_clustered[label]\n",
    "                cluster_idx = np.random.randint(0, feat.shape[0])\n",
    "\n",
    "                idx = (inst == int(i)).nonzero()\n",
    "                for k in range(self.opt.feat_num):\n",
    "                    feat_map[idx[:, 0], idx[:, 1] + k, idx[:, 2], idx[:, 3]] = feat[cluster_idx, k]\n",
    "        if self.opt.data_type == 16:\n",
    "            feat_map = feat_map.half()\n",
    "        return feat_map\n",
    "\n",
    "    def encode_features(self, image, inst):\n",
    "        image = Variable(image.cuda(), volatile=True)\n",
    "        feat_num = self.opt.feat_num\n",
    "        h, w = inst.size()[2], inst.size()[3]\n",
    "        block_num = 32\n",
    "        feat_map = self.netE.forward(image, inst.cuda())\n",
    "        inst_np = inst.cpu().numpy().astype(int)\n",
    "        feature = {}\n",
    "        for i in range(self.opt.label_nc):\n",
    "            feature[i] = np.zeros((0, feat_num + 1))\n",
    "        for i in np.unique(inst_np):\n",
    "            label = i if i < 1000 else i // 1000\n",
    "            idx = (inst == int(i)).nonzero()\n",
    "            num = idx.size()[0]\n",
    "            idx = idx[num // 2, :]\n",
    "            val = np.zeros((1, feat_num + 1))\n",
    "            for k in range(feat_num):\n",
    "                val[0, k] = feat_map[idx[0], idx[1] + k, idx[2], idx[3]].data[0]\n",
    "            val[0, feat_num] = float(num) / (h * w // block_num)\n",
    "            feature[label] = np.append(feature[label], val, axis=0)\n",
    "        return feature\n",
    "\n",
    "    def get_edges(self, t):\n",
    "        edge = torch.cuda.ByteTensor(t.size()).zero_()\n",
    "        edge[:, :, :, 1:] = edge[:, :, :, 1:] | (t[:, :, :, 1:] != t[:, :, :, :-1])\n",
    "        edge[:, :, :, :-1] = edge[:, :, :, :-1] | (t[:, :, :, 1:] != t[:, :, :, :-1])\n",
    "        edge[:, :, 1:, :] = edge[:, :, 1:, :] | (t[:, :, 1:, :] != t[:, :, :-1, :])\n",
    "        edge[:, :, :-1, :] = edge[:, :, :-1, :] | (t[:, :, 1:, :] != t[:, :, :-1, :])\n",
    "        if self.opt.data_type == 16:\n",
    "            return edge.half()\n",
    "        else:\n",
    "            return edge.float()\n",
    "\n",
    "    def save(self, which_epoch):\n",
    "        self.save_network(self.netG, 'G', which_epoch, self.gpu_ids)\n",
    "        self.save_network(self.netD, 'D', which_epoch, self.gpu_ids)\n",
    "        if self.gen_features:\n",
    "            self.save_network(self.netE, 'E', which_epoch, self.gpu_ids)\n",
    "\n",
    "    def update_fixed_params(self):\n",
    "        # after fixing the global generator for a number of iterations, also start finetuning it\n",
    "        params = list(self.netG.parameters())\n",
    "        if self.gen_features:\n",
    "            params += list(self.netE.parameters())\n",
    "        self.optimizer_G = torch.optim.Adam(params, lr=self.opt.lr, betas=(self.opt.beta1, 0.999))\n",
    "        if self.opt.verbose:\n",
    "            print('------------ Now also finetuning global generator -----------')\n",
    "\n",
    "    def update_learning_rate(self):\n",
    "        lrd = self.opt.lr / self.opt.niter_decay\n",
    "        lr = self.old_lr - lrd\n",
    "        for param_group in self.optimizer_D.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        for param_group in self.optimizer_G.param_groups:\n",
    "            param_group['lr'] = lr\n",
    "        if self.opt.verbose:\n",
    "            print('update learning rate: %f -> %f' % (self.old_lr, lr))\n",
    "        self.old_lr = lr\n",
    "\n",
    "\n",
    "class InferenceModel(Pix2PixHDModel):\n",
    "    def forward(self, inp):\n",
    "        label, inst = inp\n",
    "        return self.inference(label, inst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sixth-detective",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converts a Tensor into a Numpy array\n",
    "# |imtype|: the desired type of the converted numpy array\n",
    "def tensor2im(image_tensor, imtype=np.uint8, normalize=True):\n",
    "    if isinstance(image_tensor, list):\n",
    "        image_numpy = []\n",
    "        for i in range(len(image_tensor)):\n",
    "            image_numpy.append(tensor2im(image_tensor[i], imtype, normalize))\n",
    "        return image_numpy\n",
    "    image_numpy = image_tensor.cpu().float().numpy()\n",
    "    if normalize:\n",
    "        image_numpy = (np.transpose(image_numpy, (1, 2, 0)) + 1) / 2.0 * 255.0\n",
    "    else:\n",
    "        image_numpy = np.transpose(image_numpy, (1, 2, 0)) * 255.0      \n",
    "    image_numpy = np.clip(image_numpy, 0, 255)\n",
    "    if image_numpy.shape[2] == 1 or image_numpy.shape[2] > 3:        \n",
    "        image_numpy = image_numpy[:,:,0]\n",
    "    return image_numpy.astype(imtype)\n",
    "\n",
    "# Converts a one-hot tensor into a colorful label map\n",
    "def tensor2label(label_tensor, n_label, imtype=np.uint8):\n",
    "    if n_label == 0:\n",
    "        return tensor2im(label_tensor, imtype)\n",
    "    label_tensor = label_tensor.cpu().float()    \n",
    "    if label_tensor.size()[0] > 1:\n",
    "        label_tensor = label_tensor.max(0, keepdim=True)[1]\n",
    "    label_tensor = Colorize(n_label)(label_tensor)\n",
    "    label_numpy = np.transpose(label_tensor.numpy(), (1, 2, 0))\n",
    "    return label_numpy.astype(imtype)\n",
    "\n",
    "def save_image(image_numpy, image_path):\n",
    "    image_pil = Image.fromarray(image_numpy)\n",
    "    image_pil.save(image_path)\n",
    "\n",
    "def mkdirs(paths):\n",
    "    if isinstance(paths, list) and not isinstance(paths, str):\n",
    "        for path in paths:\n",
    "            mkdir(path)\n",
    "    else:\n",
    "        mkdir(paths)\n",
    "\n",
    "def mkdir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "###############################################################################\n",
    "# Code from\n",
    "# https://github.com/ycszen/pytorch-seg/blob/master/transform.py\n",
    "# Modified so it complies with the Citscape label map colors\n",
    "###############################################################################\n",
    "def uint82bin(n, count=8):\n",
    "    \"\"\"returns the binary of integer n, count refers to amount of bits\"\"\"\n",
    "    return ''.join([str((n >> y) & 1) for y in range(count-1, -1, -1)])\n",
    "\n",
    "def labelcolormap(N):\n",
    "    if N == 35: # cityscape\n",
    "        cmap = np.array([(  0,  0,  0), (  0,  0,  0), (  0,  0,  0), (  0,  0,  0), (  0,  0,  0), (111, 74,  0), ( 81,  0, 81),\n",
    "                     (128, 64,128), (244, 35,232), (250,170,160), (230,150,140), ( 70, 70, 70), (102,102,156), (190,153,153),\n",
    "                     (180,165,180), (150,100,100), (150,120, 90), (153,153,153), (153,153,153), (250,170, 30), (220,220,  0),\n",
    "                     (107,142, 35), (152,251,152), ( 70,130,180), (220, 20, 60), (255,  0,  0), (  0,  0,142), (  0,  0, 70),\n",
    "                     (  0, 60,100), (  0,  0, 90), (  0,  0,110), (  0, 80,100), (  0,  0,230), (119, 11, 32), (  0,  0,142)], \n",
    "                     dtype=np.uint8)\n",
    "    else:\n",
    "        cmap = np.zeros((N, 3), dtype=np.uint8)\n",
    "        for i in range(N):\n",
    "            r, g, b = 0, 0, 0\n",
    "            id = i\n",
    "            for j in range(7):\n",
    "                str_id = uint82bin(id)\n",
    "                r = r ^ (np.uint8(str_id[-1]) << (7-j))\n",
    "                g = g ^ (np.uint8(str_id[-2]) << (7-j))\n",
    "                b = b ^ (np.uint8(str_id[-3]) << (7-j))\n",
    "                id = id >> 3\n",
    "            cmap[i, 0] = r\n",
    "            cmap[i, 1] = g\n",
    "            cmap[i, 2] = b\n",
    "    return cmap\n",
    "\n",
    "class Colorize(object):\n",
    "    def __init__(self, n=35):\n",
    "        self.cmap = labelcolormap(n)\n",
    "        self.cmap = torch.from_numpy(self.cmap[:n])\n",
    "\n",
    "    def __call__(self, gray_image):\n",
    "        size = gray_image.size()\n",
    "        color_image = torch.ByteTensor(3, size[1], size[2]).fill_(0)\n",
    "\n",
    "        for label in range(0, len(self.cmap)):\n",
    "            mask = (label == gray_image[0]).cpu()\n",
    "            color_image[0][mask] = self.cmap[label][0]\n",
    "            color_image[1][mask] = self.cmap[label][1]\n",
    "            color_image[2][mask] = self.cmap[label][2]\n",
    "\n",
    "        return color_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseOptions():\n",
    "    def __init__(self):\n",
    "        self.parser = argparse.ArgumentParser()\n",
    "        self.initialized = False\n",
    "\n",
    "    def initialize(self):    \n",
    "        # experiment specifics\n",
    "        self.parser.add_argument('--name', type=str, default='label2city', help='name of the experiment. It decides where to store samples and models')        \n",
    "        self.parser.add_argument('--gpu_ids', type=str, default='0', help='gpu ids: e.g. 0  0,1,2, 0,2. use -1 for CPU')\n",
    "        self.parser.add_argument('--checkpoints_dir', type=str, default='./checkpoints', help='models are saved here')\n",
    "        self.parser.add_argument('--model', type=str, default='pix2pixHD', help='which model to use')\n",
    "        self.parser.add_argument('--norm', type=str, default='instance', help='instance normalization or batch normalization')        \n",
    "        self.parser.add_argument('--use_dropout', action='store_true', help='use dropout for the generator')\n",
    "        self.parser.add_argument('--data_type', default=32, type=int, choices=[8, 16, 32], help=\"Supported data type i.e. 8, 16, 32 bit\")\n",
    "        self.parser.add_argument('--verbose', action='store_true', default=False, help='toggles verbose')\n",
    "\n",
    "        # input/output sizes       \n",
    "        self.parser.add_argument('--batchSize', type=int, default=1, help='input batch size')\n",
    "        self.parser.add_argument('--loadSize', type=int, default=1024, help='scale images to this size')\n",
    "        self.parser.add_argument('--fineSize', type=int, default=512, help='then crop to this size')\n",
    "        self.parser.add_argument('--label_nc', type=int, default=35, help='# of input label channels')\n",
    "        self.parser.add_argument('--input_nc', type=int, default=3, help='# of input image channels')\n",
    "        self.parser.add_argument('--output_nc', type=int, default=3, help='# of output image channels')\n",
    "\n",
    "        # for setting inputs\n",
    "        self.parser.add_argument('--dataroot', type=str, default='./datasets/cityscapes/') \n",
    "        self.parser.add_argument('--resize_or_crop', type=str, default='scale_width', help='scaling and cropping of images at load time [resize_and_crop|crop|scale_width|scale_width_and_crop]')\n",
    "        self.parser.add_argument('--serial_batches', action='store_true', help='if true, takes images in order to make batches, otherwise takes them randomly')        \n",
    "        self.parser.add_argument('--no_flip', action='store_true', help='if specified, do not flip the images for data argumentation') \n",
    "        self.parser.add_argument('--nThreads', default=2, type=int, help='# threads for loading data')                \n",
    "        self.parser.add_argument('--max_dataset_size', type=int, default=float(\"inf\"), help='Maximum number of samples allowed per dataset. If the dataset directory contains more than max_dataset_size, only a subset is loaded.')\n",
    "\n",
    "        # for displays\n",
    "        self.parser.add_argument('--display_winsize', type=int, default=512,  help='display window size')\n",
    "        self.parser.add_argument('--tf_log', action='store_true', help='if specified, use tensorboard logging. Requires tensorflow installed')\n",
    "\n",
    "        # for generator\n",
    "        self.parser.add_argument('--netG', type=str, default='global', help='selects model to use for netG')\n",
    "        self.parser.add_argument('--ngf', type=int, default=64, help='# of gen filters in first conv layer')\n",
    "        self.parser.add_argument('--n_downsample_global', type=int, default=4, help='number of downsampling layers in netG') \n",
    "        self.parser.add_argument('--n_blocks_global', type=int, default=9, help='number of residual blocks in the global generator network')\n",
    "        self.parser.add_argument('--n_blocks_local', type=int, default=3, help='number of residual blocks in the local enhancer network')\n",
    "        self.parser.add_argument('--n_local_enhancers', type=int, default=1, help='number of local enhancers to use')        \n",
    "        self.parser.add_argument('--niter_fix_global', type=int, default=0, help='number of epochs that we only train the outmost local enhancer')        \n",
    "\n",
    "        # for instance-wise features\n",
    "        self.parser.add_argument('--no_instance', action='store_true', help='if specified, do *not* add instance map as input')        \n",
    "        self.parser.add_argument('--instance_feat', action='store_true', help='if specified, add encoded instance features as input')\n",
    "        self.parser.add_argument('--label_feat', action='store_true', help='if specified, add encoded label features as input')        \n",
    "        self.parser.add_argument('--feat_num', type=int, default=3, help='vector length for encoded features')        \n",
    "        self.parser.add_argument('--load_features', action='store_true', help='if specified, load precomputed feature maps')\n",
    "        self.parser.add_argument('--n_downsample_E', type=int, default=4, help='# of downsampling layers in encoder') \n",
    "        self.parser.add_argument('--nef', type=int, default=16, help='# of encoder filters in the first conv layer')        \n",
    "        self.parser.add_argument('--n_clusters', type=int, default=10, help='number of clusters for features')\n",
    "\n",
    "        self.parser.add_argument('--use_rgb', default=True, help='for using prev')\n",
    "\n",
    "\n",
    "\n",
    "        self.initialized = True\n",
    "\n",
    "    def parse(self, save=True):\n",
    "        if not self.initialized:\n",
    "            self.initialize()\n",
    "        self.opt = self.parser.parse_args()\n",
    "        self.opt.isTrain = self.isTrain   # train or test\n",
    "\n",
    "        str_ids = self.opt.gpu_ids.split(',')\n",
    "        self.opt.gpu_ids = []\n",
    "        for str_id in str_ids:\n",
    "            id = int(str_id)\n",
    "            if id >= 0:\n",
    "                self.opt.gpu_ids.append(id)\n",
    "        \n",
    "        # set gpu ids\n",
    "        if len(self.opt.gpu_ids) > 0:\n",
    "            torch.cuda.set_device(self.opt.gpu_ids[0])\n",
    "\n",
    "        args = vars(self.opt)\n",
    "\n",
    "        print('------------ Options -------------')\n",
    "        for k, v in sorted(args.items()):\n",
    "            print('%s: %s' % (str(k), str(v)))\n",
    "        print('-------------- End ----------------')\n",
    "\n",
    "        # save to the disk        \n",
    "        expr_dir = os.path.join(self.opt.checkpoints_dir, self.opt.name)\n",
    "        util.mkdirs(expr_dir)\n",
    "        if save and not self.opt.continue_train:\n",
    "            file_name = os.path.join(expr_dir, 'opt.txt')\n",
    "            with open(file_name, 'wt') as opt_file:\n",
    "                opt_file.write('------------ Options -------------\\n')\n",
    "                for k, v in sorted(args.items()):\n",
    "                    opt_file.write('%s: %s\\n' % (str(k), str(v)))\n",
    "                opt_file.write('-------------- End ----------------\\n')\n",
    "        return self.opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggressive-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainOptions(BaseOptions):\n",
    "    def initialize(self):\n",
    "        BaseOptions.initialize(self)\n",
    "        # for displays\n",
    "        self.parser.add_argument('--display_freq', type=int, default=100, help='frequency of showing training results on screen')\n",
    "        self.parser.add_argument('--print_freq', type=int, default=100, help='frequency of showing training results on console')\n",
    "        self.parser.add_argument('--save_latest_freq', type=int, default=1000, help='frequency of saving the latest results')\n",
    "        self.parser.add_argument('--save_epoch_freq', type=int, default=10, help='frequency of saving checkpoints at the end of epochs')        \n",
    "        self.parser.add_argument('--no_html', action='store_true', help='do not save intermediate training results to [opt.checkpoints_dir]/[opt.name]/web/')\n",
    "        self.parser.add_argument('--debug', action='store_true', help='only do one epoch and displays at each iteration')\n",
    "\n",
    "        # for training\n",
    "        self.parser.add_argument('--continue_train', action='store_true', help='continue training: load the latest model')\n",
    "        self.parser.add_argument('--load_pretrain', type=str, default='', help='load the pretrained model from the specified location')\n",
    "        self.parser.add_argument('--which_epoch', type=str, default='latest', help='which epoch to load? set to latest to use latest cached model')\n",
    "        self.parser.add_argument('--phase', type=str, default='train', help='train, val, test, etc')\n",
    "        self.parser.add_argument('--niter', type=int, default=100, help='# of iter at starting learning rate')\n",
    "        self.parser.add_argument('--niter_decay', type=int, default=100, help='# of iter to linearly decay learning rate to zero')\n",
    "        self.parser.add_argument('--beta1', type=float, default=0.5, help='momentum term of adam')\n",
    "        self.parser.add_argument('--lr', type=float, default=0.0002, help='initial learning rate for adam')\n",
    "\n",
    "        # for discriminators        \n",
    "        self.parser.add_argument('--num_D', type=int, default=2, help='number of discriminators to use')\n",
    "        self.parser.add_argument('--n_layers_D', type=int, default=3, help='only used if which_model_netD==n_layers')\n",
    "        self.parser.add_argument('--ndf', type=int, default=64, help='# of discrim filters in first conv layer')    \n",
    "        self.parser.add_argument('--lambda_feat', type=float, default=10.0, help='weight for feature matching loss')                \n",
    "        self.parser.add_argument('--no_ganFeat_loss', action='store_true', help='if specified, do *not* use discriminator feature matching loss')\n",
    "        self.parser.add_argument('--no_vgg_loss', action='store_true', help='if specified, do *not* use VGG feature matching loss')        \n",
    "        self.parser.add_argument('--no_lsgan', action='store_true', help='do *not* use least square GAN, if false, use vanilla GAN')\n",
    "        self.parser.add_argument('--pool_size', type=int, default=0, help='the size of image buffer that stores previously generated images')\n",
    "\n",
    "        self.isTrain = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-register",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = TrainOptions().parse()\n",
    "iter_path = os.path.join(opt.checkpoints_dir, opt.name, 'iter.txt')\n",
    "if opt.continue_train:\n",
    "    try:\n",
    "        start_epoch, epoch_iter = np.loadtxt(iter_path , delimiter=',', dtype=int)\n",
    "    except:\n",
    "        start_epoch, epoch_iter = 1, 0\n",
    "    print('Resuming from epoch %d at iteration %d' % (start_epoch, epoch_iter))        \n",
    "else:    \n",
    "    start_epoch, epoch_iter = 1, 0\n",
    "\n",
    "opt.print_freq = lcm(opt.print_freq, opt.batchSize)    \n",
    "if opt.debug:\n",
    "    opt.display_freq = 1\n",
    "    opt.print_freq = 1\n",
    "    opt.niter = 1\n",
    "    opt.niter_decay = 0\n",
    "    opt.max_dataset_size = 10\n",
    "\n",
    "data_loader = CreateDataLoader(opt)\n",
    "dataset = data_loader.load_data()\n",
    "dataset_size = len(data_loader)\n",
    "print('#training images = %d' % dataset_size)\n",
    "\n",
    "model = create_model(opt)\n",
    "visualizer = Visualizer(opt)\n",
    "#if opt.fp16:    \n",
    "#    from apex import amp\n",
    "#    model, [optimizer_G, optimizer_D] = amp.initialize(model, [model.optimizer_G, model.optimizer_D], opt_level='O1')             \n",
    "#    model = torch.nn.DataParallel(model, device_ids=opt.gpu_ids)\n",
    "#else:\n",
    "optimizer_G, optimizer_D = model.module.optimizer_G, model.module.optimizer_D\n",
    "\n",
    "total_steps = (start_epoch-1) * dataset_size + epoch_iter\n",
    "\n",
    "display_delta = total_steps % opt.display_freq\n",
    "print_delta = total_steps % opt.print_freq\n",
    "save_delta = total_steps % opt.save_latest_freq\n",
    "\n",
    "for epoch in range(start_epoch, opt.niter + opt.niter_decay + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    if epoch != start_epoch:\n",
    "        epoch_iter = epoch_iter % dataset_size\n",
    "    for i, data in enumerate(dataset, start=epoch_iter):\n",
    "        if total_steps % opt.print_freq == print_delta:\n",
    "            iter_start_time = time.time()\n",
    "        total_steps += opt.batchSize\n",
    "        epoch_iter += opt.batchSize\n",
    "\n",
    "        # whether to collect output images\n",
    "        save_fake = total_steps % opt.display_freq == display_delta\n",
    "\n",
    "        ############## Forward Pass ######################\n",
    "        losses, generated = model(Variable(data['label']), Variable(data['inst']), \n",
    "            Variable(data['image']), Variable(data['feat']), infer=save_fake)\n",
    "\n",
    "        # sum per device losses\n",
    "        losses = [ torch.mean(x) if not isinstance(x, int) else x for x in losses ]\n",
    "        loss_dict = dict(zip(model.module.loss_names, losses))\n",
    "\n",
    "        # calculate final loss scalar\n",
    "        loss_D = (loss_dict['D_fake'] + loss_dict['D_real']) * 0.5\n",
    "        loss_G = loss_dict['G_GAN'] + loss_dict.get('G_GAN_Feat',0) + loss_dict.get('G_VGG',0)\n",
    "\n",
    "        ############### Backward Pass ####################\n",
    "        # update generator weights\n",
    "        optimizer_G.zero_grad()\n",
    "        #if opt.fp16:                                \n",
    "        #    with amp.scale_loss(loss_G, optimizer_G) as scaled_loss: scaled_loss.backward()                \n",
    "        #else:\n",
    "        loss_G.backward()          \n",
    "        optimizer_G.step()\n",
    "\n",
    "        # update discriminator weights\n",
    "        optimizer_D.zero_grad()\n",
    "        #if opt.fp16:                                \n",
    "        #    with amp.scale_loss(loss_D, optimizer_D) as scaled_loss: scaled_loss.backward()                \n",
    "        #else:\n",
    "        loss_D.backward()        \n",
    "        optimizer_D.step()        \n",
    "\n",
    "        ############## Display results and errors ##########\n",
    "        ### print out errors\n",
    "        if total_steps % opt.print_freq == print_delta:\n",
    "            errors = {k: v.data.item() if not isinstance(v, int) else v for k, v in loss_dict.items()}            \n",
    "            t = (time.time() - iter_start_time) / opt.print_freq\n",
    "            visualizer.print_current_errors(epoch, epoch_iter, errors, t)\n",
    "            visualizer.plot_current_errors(errors, total_steps)\n",
    "            #call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=memory.used,memory.free\"]) \n",
    "\n",
    "        ### display output images\n",
    "        if save_fake:\n",
    "            visuals = OrderedDict([('input_label', util.tensor2label(data['label'][0], opt.label_nc)),\n",
    "                                   ('synthesized_image', util.tensor2im(generated.data[0])),\n",
    "                                   ('real_image', util.tensor2im(data['image'][0]))])\n",
    "            visualizer.display_current_results(visuals, epoch, total_steps)\n",
    "\n",
    "        ### save latest model\n",
    "        if total_steps % opt.save_latest_freq == save_delta:\n",
    "            print('saving the latest model (epoch %d, total_steps %d)' % (epoch, total_steps))\n",
    "            model.module.save('latest')            \n",
    "            np.savetxt(iter_path, (epoch, epoch_iter), delimiter=',', fmt='%d')\n",
    "\n",
    "        if epoch_iter >= dataset_size:\n",
    "            break\n",
    "       \n",
    "    # end of epoch \n",
    "    iter_end_time = time.time()\n",
    "    print('End of epoch %d / %d \\t Time Taken: %d sec' %\n",
    "          (epoch, opt.niter + opt.niter_decay, time.time() - epoch_start_time))\n",
    "\n",
    "    ### save model for this epoch\n",
    "    if epoch % opt.save_epoch_freq == 0:\n",
    "        print('saving the model at the end of epoch %d, iters %d' % (epoch, total_steps))        \n",
    "        model.module.save('latest')\n",
    "        model.module.save(epoch)\n",
    "        np.savetxt(iter_path, (epoch+1, 0), delimiter=',', fmt='%d')\n",
    "\n",
    "    ### instead of only training the local enhancer, train the entire network after certain iterations\n",
    "    if (opt.niter_fix_global != 0) and (epoch == opt.niter_fix_global):\n",
    "        model.module.update_fixed_params()\n",
    "\n",
    "    ### linearly decay learning rate after certain iterations\n",
    "    if epoch > opt.niter:\n",
    "        model.module.update_learning_rate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
