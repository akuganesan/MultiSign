{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import utils.dataset as dataset\n",
    "import utils.skel as skel\n",
    "\n",
    "from utils.dataset import SIGNUMDataset\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USING DATASET TO GENERATE MEAN AND STD\n",
      "2496\n"
     ]
    }
   ],
   "source": [
    "test_dataset = SIGNUMDataset('/scratch/datasets/SIGNUM', use_pose=True, subsample=10, gen_constants=True, training=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=0, collate_fn=test_dataset.collate)\n",
    "print(len(test_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n"
     ]
    }
   ],
   "source": [
    "all_poses = []\n",
    "for i, data in enumerate(test_dataloader):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "#     img_seq = data['img_seq'] # commented out because we don't want to waste time openning photos\n",
    "    pose_seq = data['pose_seq'].squeeze(0)\n",
    "#     print(pose_seq.shape)\n",
    "    for pose in pose_seq:\n",
    "        all_poses.append(pose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57014\n",
      "torch.Size([57014, 57, 2])\n"
     ]
    }
   ],
   "source": [
    "print(len(all_poses))\n",
    "all_poses = torch.stack(all_poses)\n",
    "print(all_poses.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([57, 2])\n",
      "tensor([[-6.6026e-01, -9.0518e+01],\n",
      "        [ 0.0000e+00,  0.0000e+00],\n",
      "        [-7.0755e+01, -7.3369e-01],\n",
      "        [-1.0581e+02,  1.1330e+02],\n",
      "        [-8.2491e+01,  1.2775e+02],\n",
      "        [ 7.1765e+01,  8.3194e-01],\n",
      "        [ 9.7475e+01,  1.2009e+02],\n",
      "        [ 8.9166e+01,  1.9322e+02],\n",
      "        [-3.1799e-02,  2.2469e+02],\n",
      "        [-4.6118e+01,  2.2498e+02],\n",
      "        [ 4.6777e+01,  2.2560e+02],\n",
      "        [-1.5540e+01, -1.0390e+02],\n",
      "        [ 1.4438e+01, -1.0450e+02],\n",
      "        [-3.5294e+01, -9.2407e+01],\n",
      "        [ 3.6171e+01, -9.3271e+01],\n",
      "        [ 8.7430e+01,  1.9621e+02],\n",
      "        [ 7.7883e+01,  1.9989e+02],\n",
      "        [ 6.9933e+01,  2.0795e+02],\n",
      "        [ 6.6022e+01,  2.1744e+02],\n",
      "        [ 6.3389e+01,  2.2440e+02],\n",
      "        [ 8.0726e+01,  2.1709e+02],\n",
      "        [ 7.4045e+01,  2.2790e+02],\n",
      "        [ 6.8585e+01,  2.3156e+02],\n",
      "        [ 6.5045e+01,  2.3401e+02],\n",
      "        [ 8.6108e+01,  2.1940e+02],\n",
      "        [ 7.8216e+01,  2.2968e+02],\n",
      "        [ 7.2233e+01,  2.3209e+02],\n",
      "        [ 6.7675e+01,  2.3284e+02],\n",
      "        [ 8.9785e+01,  2.1966e+02],\n",
      "        [ 8.2716e+01,  2.2843e+02],\n",
      "        [ 7.6715e+01,  2.3059e+02],\n",
      "        [ 7.2083e+01,  2.3100e+02],\n",
      "        [ 9.1756e+01,  2.1870e+02],\n",
      "        [ 8.6616e+01,  2.2631e+02],\n",
      "        [ 8.2194e+01,  2.2821e+02],\n",
      "        [ 7.8744e+01,  2.2850e+02],\n",
      "        [-7.9982e+01,  1.2723e+02],\n",
      "        [-7.1645e+01,  1.2651e+02],\n",
      "        [-6.2864e+01,  1.2687e+02],\n",
      "        [-5.7486e+01,  1.2994e+02],\n",
      "        [-5.4798e+01,  1.3216e+02],\n",
      "        [-7.0140e+01,  1.2859e+02],\n",
      "        [-6.2470e+01,  1.3272e+02],\n",
      "        [-5.7216e+01,  1.3442e+02],\n",
      "        [-5.3462e+01,  1.3575e+02],\n",
      "        [-7.4374e+01,  1.3183e+02],\n",
      "        [-6.4846e+01,  1.3681e+02],\n",
      "        [-5.9610e+01,  1.3879e+02],\n",
      "        [-5.6395e+01,  1.3911e+02],\n",
      "        [-7.7159e+01,  1.3448e+02],\n",
      "        [-6.8476e+01,  1.3897e+02],\n",
      "        [-6.3619e+01,  1.4050e+02],\n",
      "        [-6.0567e+01,  1.4064e+02],\n",
      "        [-7.8762e+01,  1.3678e+02],\n",
      "        [-7.2222e+01,  1.4072e+02],\n",
      "        [-6.8337e+01,  1.4190e+02],\n",
      "        [-6.5922e+01,  1.4186e+02]])\n"
     ]
    }
   ],
   "source": [
    "mean = torch.mean(all_poses, dim=0)\n",
    "print(mean.shape)\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([57, 2])\n",
      "tensor([[  5.5448,   9.2911],\n",
      "        [  0.0000,   0.0000],\n",
      "        [  5.8394,   3.2619],\n",
      "        [ 19.2988,  17.3876],\n",
      "        [ 27.2576,  92.1078],\n",
      "        [  6.1881,   3.5891],\n",
      "        [ 14.7989,  12.8894],\n",
      "        [ 21.1021,  68.6420],\n",
      "        [  4.2068,  17.7830],\n",
      "        [  5.9991,  17.3661],\n",
      "        [  4.2529,  17.8924],\n",
      "        [  5.4826,   8.7215],\n",
      "        [  5.1135,   8.7034],\n",
      "        [  7.6450,   7.5764],\n",
      "        [  7.1400,   8.0365],\n",
      "        [ 23.6164,  71.4964],\n",
      "        [ 22.4616,  77.6791],\n",
      "        [ 24.1505,  87.8202],\n",
      "        [ 26.8883,  96.5423],\n",
      "        [ 29.0920, 103.1725],\n",
      "        [ 28.7113,  93.8150],\n",
      "        [ 31.6147, 102.2195],\n",
      "        [ 32.3005, 105.3503],\n",
      "        [ 33.0954, 107.4717],\n",
      "        [ 30.3545,  91.7822],\n",
      "        [ 33.6856,  99.4768],\n",
      "        [ 34.0618, 101.6141],\n",
      "        [ 34.2840, 103.0223],\n",
      "        [ 31.5583,  88.4734],\n",
      "        [ 34.8853,  95.0361],\n",
      "        [ 34.9204,  97.0993],\n",
      "        [ 34.7770,  98.5054],\n",
      "        [ 32.5748,  84.3899],\n",
      "        [ 35.4199,  89.8136],\n",
      "        [ 35.4740,  91.6570],\n",
      "        [ 35.4015,  92.7523],\n",
      "        [ 30.2105,  96.5263],\n",
      "        [ 30.0377, 104.1719],\n",
      "        [ 33.4435, 116.5116],\n",
      "        [ 37.5650, 126.9800],\n",
      "        [ 40.8034, 134.7822],\n",
      "        [ 38.7038, 126.1478],\n",
      "        [ 43.3329, 136.3660],\n",
      "        [ 44.7583, 139.5619],\n",
      "        [ 46.0066, 141.7701],\n",
      "        [ 40.4968, 124.1702],\n",
      "        [ 45.2432, 132.6465],\n",
      "        [ 45.0604, 133.7293],\n",
      "        [ 44.8119, 134.1707],\n",
      "        [ 41.6624, 120.3687],\n",
      "        [ 46.1035, 127.4313],\n",
      "        [ 45.3475, 128.2249],\n",
      "        [ 44.6510, 128.6435],\n",
      "        [ 42.6337, 115.6255],\n",
      "        [ 46.1456, 121.4789],\n",
      "        [ 45.5501, 122.5340],\n",
      "        [ 44.8979, 122.8576]])\n"
     ]
    }
   ],
   "source": [
    "std = torch.std(all_poses, dim=0)\n",
    "print(std.shape)\n",
    "print(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "532",
   "language": "python",
   "name": "532"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
